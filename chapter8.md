# 第 8 章：自动微分与梯度优化

自动微分是现代AI编译器的核心功能之一，它使得深度学习框架能够自动计算复杂神经网络的梯度，而无需手动推导。在200T参数规模的模型训练中，高效的自动微分实现直接决定了训练的可行性。本章将深入探讨自动微分的编译器实现原理，重点关注内存优化、计算效率和数值稳定性三个关键维度。

## 8.1 自动微分基础

### 8.1.1 三种微分方法对比

在计算函数导数时，我们有三种基本方法：

**符号微分**：基于微分规则对表达式进行符号操作，生成导数的解析表达式。例如，对于 $f(x) = x^2 + \sin(x)$，符号微分得到 $f'(x) = 2x + \cos(x)$。

优点：
- 得到精确的解析表达式
- 可以进行进一步的符号简化

缺点：
- 表达式膨胀问题严重
- 难以处理控制流
- 实现复杂度高

**数值微分**：使用有限差分近似计算导数：

$$\frac{\partial f}{\partial x_i} \approx \frac{f(x + h \cdot e_i) - f(x - h \cdot e_i)}{2h}$$

其中 $h$ 是小的扰动量，$e_i$ 是第 $i$ 个单位向量。

优点：
- 实现简单
- 可以作为验证工具

缺点：
- 截断误差和舍入误差的权衡
- 计算复杂度为 $O(n)$ 次前向计算
- 数值不稳定

**自动微分**：基于链式法则，在计算原函数的同时计算导数。这是AI编译器采用的主要方法。

### 8.1.2 计算图表示

在AI编译器中，计算图是自动微分的基础数据结构。每个节点代表一个操作，边代表数据依赖。

```
     输入层        隐藏层         输出层
    x -----> [W1*x+b1] -----> [ReLU] -----> [W2*h+b2] -----> y
         ↑            ↑                   ↑            ↑
        W1,b1      激活函数             W2,b2       损失函数
```

对于计算图 $\mathcal{G} = (V, E)$，每个节点 $v \in V$ 包含：
- 前向计算函数：$f_v: \mathbb{R}^{n_{in}} \rightarrow \mathbb{R}^{n_{out}}$
- 局部雅可比矩阵：$J_v = \frac{\partial f_v}{\partial x}$
- 反向传播函数：$b_v: \mathbb{R}^{n_{out}} \rightarrow \mathbb{R}^{n_{in}}$

### 8.1.3 链式法则的高效实现

链式法则是自动微分的数学基础。对于复合函数 $y = f(g(h(x)))$，其导数为：

$$\frac{dy}{dx} = \frac{dy}{dg} \cdot \frac{dg}{dh} \cdot \frac{dh}{dx}$$

在高维情况下，这变成雅可比矩阵的乘积。关键优化在于选择计算顺序：
- 从右到左（反向模式）：适合输出维度小于输入维度
- 从左到右（前向模式）：适合输入维度小于输出维度

## 8.2 前向模式与反向模式自动微分

### 8.2.1 前向模式自动微分

前向模式AD（也称为切线模式）沿着计算图的前向方向传播导数。对于函数 $y = f(x)$，我们同时计算：

$$\dot{y} = \frac{\partial f}{\partial x} \cdot \dot{x}$$

其中 $\dot{x}$ 是输入的切线向量（通常是单位向量）。

**双数（Dual Numbers）表示**：

前向模式可以通过双数算术优雅地实现。定义双数为 $a + b\epsilon$，其中 $\epsilon^2 = 0$。运算规则：

$$(a + b\epsilon) + (c + d\epsilon) = (a + c) + (b + d)\epsilon$$
$$(a + b\epsilon) \cdot (c + d\epsilon) = ac + (ad + bc)\epsilon$$

**复杂度分析**：

对于 $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$：
- 计算完整雅可比矩阵需要 $n$ 次前向传播
- 每次传播的复杂度是 $O(ops(f))$
- 总复杂度：$O(n \cdot ops(f))$

**应用场景**：

前向模式在以下场景效率更高：
1. 计算 Jacobian-vector product (JVP)
2. 输入维度远小于输出维度（如 ODE 求解）
3. 计算方向导数

### 8.2.2 反向模式自动微分

反向模式AD（也称为伴随模式）是深度学习框架的标准选择。它沿着计算图的反向传播梯度。

**数学原理**：

给定标量损失函数 $L = f(x)$，反向模式计算：

$$\bar{x} = \frac{\partial L}{\partial x} = \left(\frac{\partial f}{\partial x}\right)^T \bar{y}$$

其中 $\bar{y} = \frac{\partial L}{\partial y}$ 是输出的伴随（adjoint）。

**实现策略**：

1. **前向传播**：计算所有中间值并存储
2. **反向传播**：从输出开始，逐层计算梯度

对于节点 $v$ 的局部梯度计算：

$$\bar{x}_v = \sum_{u \in \text{children}(v)} \left(\frac{\partial f_u}{\partial x_v}\right)^T \bar{y}_u$$

**内存管理**：

反向模式需要存储前向传播的中间结果，内存需求为：

$$M_{reverse} = \sum_{v \in V} size(v_{output}) + size(v_{state})$$

其中 $v_{state}$ 是计算梯度所需的额外状态。

### 8.2.3 混合模式策略

对于复杂网络，单一模式可能不是最优的。混合模式策略包括：

**1. 分块混合**：
将计算图分成子图，每个子图选择最优模式：
- 识别瓶颈层（如全连接层）使用反向模式
- 识别扇出层（如多头注意力）考虑前向模式

**2. 嵌套自动微分**：
对于需要计算高阶导数的情况，可以嵌套使用不同模式：
```
外层：反向模式计算一阶梯度
内层：前向模式计算 Hessian-vector product
```

**3. 选择性模式切换**：
基于运行时信息动态选择：
- 监控内存压力
- 评估计算/内存权衡
- 根据批大小调整策略

## 8.3 检查点策略

### 8.3.1 内存与计算的基本权衡

在训练200T参数模型时，激活值的内存占用可能达到TB级别。检查点（Checkpointing）通过选择性地存储中间结果，在需要时重新计算，实现内存与计算的权衡。

**内存占用模型**：

对于 $L$ 层的网络，设每层激活值大小为 $m$：
- 无检查点：$M_{total} = L \cdot m$
- 全检查点：$M_{total} = m$（但需要 $L$ 倍重计算）
- 最优检查点：$M_{total} = O(\sqrt{L} \cdot m)$

### 8.3.2 最优检查点算法

**动态规划方法**：

定义 $C(n, k)$ 为在 $n$ 层网络中使用 $k$ 个检查点的最小计算代价。递推关系：

$$C(n, k) = \min_{1 \leq i \leq n-1} \{C(i, k-1) + C(n-i, k) + i\}$$

边界条件：
- $C(n, 0) = \frac{n(n+1)}{2}$（无检查点，全部重计算）
- $C(n, n) = n$（全部检查点）

**启发式算法**：

对于深度网络，常用的启发式包括：

1. **均匀检查点**：每隔 $\sqrt{L}$ 层设置检查点
2. **层次检查点**：递归地在中点设置检查点
3. **梯度检查点**：基于激活值大小动态决定

### 8.3.3 选择性重计算

不是所有操作都值得检查点化。选择标准：

**计算密集度评分**：
$$S_{op} = \frac{计算复杂度}{内存占用} = \frac{FLOPs}{bytes}$$

- 高分操作（如矩阵乘法）：适合重计算
- 低分操作（如激活函数）：适合存储

**依赖链分析**：
识别关键路径和可并行重计算的子图：

```
    A → B → C
    ↓   ↓   ↓
    D → E → F
```

在此图中，检查点 A 和 C 可以并行重计算 B、D、E。

### 8.3.4 动态检查点策略

在实际训练中，静态检查点策略可能不是最优的。动态策略根据运行时信息调整：

**自适应阈值算法**：

监控当前内存使用率 $\rho = \frac{M_{used}}{M_{total}}$：

```
如果 ρ > ρ_high (如 0.9):
    增加检查点密度
如果 ρ < ρ_low (如 0.5):
    减少检查点密度
```

**成本模型驱动**：

定义总成本函数：
$$Cost = \alpha \cdot T_{compute} + \beta \cdot M_{peak} + \gamma \cdot T_{swap}$$

其中：
- $T_{compute}$：重计算时间
- $M_{peak}$：峰值内存
- $T_{swap}$：换入换出时间
- $\alpha, \beta, \gamma$：权重系数

**分布式检查点**：

在多GPU训练中，可以跨设备分布检查点：
- 设备 0 存储层 1-10 的激活值
- 设备 1 存储层 11-20 的激活值
- 通过 all-gather 操作恢复

## 8.4 梯度累积优化

### 8.4.1 大批量训练的梯度累积

当单个批次无法装入内存时，梯度累积成为必要技术。基本原理：

$$\nabla L_{total} = \frac{1}{K} \sum_{k=1}^{K} \nabla L_k$$

其中 $K$ 是累积步数。

**实现策略**：

1. **原地累积**：
   ```
   梯度缓冲区 G = 0
   对于每个微批次 k:
       前向传播计算 L_k
       反向传播计算 ∇L_k
       G += ∇L_k / K
   使用 G 更新参数
   ```

2. **延迟缩放**：
   避免数值下溢：
   ```
   G = 0
   对于每个微批次 k:
       G += ∇L_k
   G = G / K  # 最后统一缩放
   ```

**内存优化**：

梯度累积的内存需求：
$$M_{grad} = M_{param} + M_{grad\_buffer} + M_{optimizer\_state}$$

对于 Adam 优化器：
$$M_{optimizer} = 3 \times M_{param}$$（参数、一阶矩、二阶矩）

### 8.4.2 梯度压缩与量化

在分布式训练中，梯度通信是瓶颈。压缩技术包括：

**1. 梯度量化**：

将 FP32 梯度量化为 INT8：
$$g_{quantized} = \text{round}\left(\frac{g - g_{min}}{g_{max} - g_{min}} \times 255\right)$$

反量化：
$$g_{recovered} = g_{quantized} \times \frac{g_{max} - g_{min}}{255} + g_{min}$$

**2. Top-K 稀疏化**：

只传输最大的 K 个梯度：
$$g_{sparse} = \begin{cases}
g_i & \text{if } |g_i| \in \text{Top-K}(|g|) \\
0 & \text{otherwise}
\end{cases}$$

压缩率：$\frac{K}{N}$，其中 $N$ 是参数总数。

**3. 误差反馈**：

累积量化误差并在下一轮补偿：
$$e_{t+1} = e_t + (g_t - g_{compressed,t})$$
$$g_{t+1,sent} = \text{compress}(g_{t+1} + e_{t+1})$$

### 8.4.3 异步梯度更新

为了隐藏通信延迟，可以实现异步更新：

**流水线并行**：
```
时刻 t:   计算层L梯度 | 传输层L-1梯度 | 更新层L-2参数
时刻 t+1: 计算层L+1梯度 | 传输层L梯度 | 更新层L-1参数
```

**局部更新策略**：
- 立即更新本地参数
- 异步同步全局参数
- 使用延迟补偿算法

$$\theta_{t+1} = \theta_t - \eta \cdot g_t - \tau \cdot (g_t - g_{t-\tau})$$

其中 $\tau$ 是延迟步数。

### 8.4.4 梯度裁剪与归一化

为了训练稳定性，需要对梯度进行处理：

**梯度裁剪**：

1. **按值裁剪**：
$$g_{clipped} = \text{clip}(g, -\theta, \theta)$$

2. **按范数裁剪**：
$$g_{clipped} = g \cdot \min\left(1, \frac{\theta}{||g||_2}\right)$$

**自适应裁剪**：

基于历史统计动态调整阈值：
$$\theta_t = \mu_{t-1} + k \cdot \sigma_{t-1}$$

其中 $\mu_{t-1}$ 和 $\sigma_{t-1}$ 是梯度范数的移动平均和标准差。

**层级归一化**：

对不同层使用不同的学习率：
$$g_{normalized}^{(l)} = \frac{g^{(l)}}{||g^{(l)}||_2 + \epsilon} \cdot \sqrt{d_l}$$

其中 $d_l$ 是第 $l$ 层的参数维度。

## 8.5 高阶导数支持

### 8.5.1 Hessian 矩阵计算

Hessian 矩阵 $H = \nabla^2 f$ 在优化算法和不确定性估计中至关重要。

**Hessian-vector product (HVP)**：

避免显式计算完整 Hessian，只计算 $Hv$：

$$Hv = \nabla_x(\nabla_x f \cdot v) = \nabla_x(g^T v)$$

实现步骤：
1. 计算梯度 $g = \nabla_x f$
2. 计算标量 $s = g^T v$
3. 对 $s$ 关于 $x$ 求导

复杂度：$O(n)$ 而非 $O(n^2)$

**Gauss-Newton 近似**：

对于最小二乘问题 $f(x) = \frac{1}{2}||r(x)||^2$：

$$H \approx J^T J$$

其中 $J$ 是残差的雅可比矩阵。

### 8.5.2 高阶优化器支持

**L-BFGS 实现**：

维护有限内存的 Hessian 近似：

$$H_k \approx B_k = (I - \rho_k s_k y_k^T) B_{k-1} (I - \rho_k y_k s_k^T) + \rho_k s_k s_k^T$$

其中：
- $s_k = x_{k+1} - x_k$
- $y_k = g_{k+1} - g_k$
- $\rho_k = \frac{1}{y_k^T s_k}$

内存需求：$O(m \cdot n)$，其中 $m$ 是历史步数（通常 5-20）。

**自然梯度**：

使用 Fisher 信息矩阵 $F$ 替代 Hessian：

$$\theta_{t+1} = \theta_t - \eta F^{-1} g$$

对于大规模网络，使用 K-FAC 近似：
$$F \approx A \otimes B$$

其中 $A$ 和 $B$ 是较小的矩阵，$\otimes$ 是 Kronecker 积。

### 8.5.3 自动微分的递归应用

计算高阶导数需要递归应用自动微分：

**二阶导数**：
```
y = f(x)
g = ∇f(x)  # 第一次自动微分
H = ∇g(x)  # 第二次自动微分
```

**挑战与优化**：

1. **内存爆炸**：高阶导数的中间变量呈指数增长
   - 解决：选择性计算，只保留需要的部分

2. **数值稳定性**：高阶导数对数值误差敏感
   - 解决：使用更高精度或符号微分验证

3. **计算图膨胀**：递归构建导致图规模激增
   - 解决：图优化和公共子表达式消除

### 8.5.4 混合精度高阶导数

在混合精度训练中，高阶导数的精度管理更加复杂：

**精度策略**：
- 一阶导数：FP16 计算，FP32 累积
- 二阶导数：FP32 计算，FP32 存储
- 参数更新：FP32 主权重

**动态损失缩放**：

对于高阶导数，需要调整缩放因子：
$$L_{scaled} = L \times s^{order}$$

其中 $order$ 是导数阶数。

**数值范围监控**：

监控各阶导数的数值范围：
$$R_k = \log_{10}\left(\frac{\max(|\nabla^k f|)}{\min(|\nabla^k f| + \epsilon)}\right)$$

当 $R_k > threshold$ 时，切换到更高精度。

## 8.6 本章小结

本章深入探讨了AI编译器中自动微分与梯度优化的核心技术。我们学习了：

1. **自动微分基础**：理解了符号微分、数值微分和自动微分的区别，掌握了计算图表示和链式法则的高效实现。

2. **前向与反向模式**：分析了两种模式的数学原理、复杂度和适用场景，以及混合模式策略的设计。

3. **检查点技术**：探讨了内存与计算的权衡，学习了最优检查点算法和动态策略。

4. **梯度优化**：涵盖了梯度累积、压缩、异步更新和数值稳定性处理。

5. **高阶导数**：理解了Hessian计算、高阶优化器支持和混合精度下的挑战。

关键公式回顾：
- 反向模式复杂度：$O(ops(f))$ 计算所有梯度
- 最优检查点内存：$O(\sqrt{L} \cdot m)$
- 梯度压缩率：$\frac{K}{N}$ (Top-K稀疏化)
- HVP复杂度：$O(n)$ 而非 $O(n^2)$

## 8.7 练习题

### 基础题

**习题 8.1**：计算复杂度分析
给定一个全连接网络，输入维度为1000，包含3个隐藏层（维度分别为500、200、100），输出维度为10。比较使用前向模式和反向模式计算完整雅可比矩阵的计算复杂度。

<details>
<summary>提示 (Hint)</summary>
考虑雅可比矩阵的维度和每种模式需要的传播次数。
</details>

<details>
<summary>答案</summary>

前向模式需要1000次传播（输入维度），每次计算一列雅可比矩阵。
反向模式需要10次传播（输出维度），每次计算一行雅可比矩阵。
因此反向模式效率更高，需要的计算量约为前向模式的1/100。

总FLOPs比较：
- 前向模式：1000 × (1000×500 + 500×200 + 200×100 + 100×10) = 6.21×10^8
- 反向模式：10 × (1000×500 + 500×200 + 200×100 + 100×10) = 6.21×10^6
</details>

**习题 8.2**：检查点内存计算
一个50层的Transformer模型，每层激活值占用2GB内存。如果使用均匀检查点策略，每隔k层设置一个检查点，求：
(a) k=5时的峰值内存占用
(b) k=10时需要的额外计算量（相对于无检查点）

<details>
<summary>提示 (Hint)</summary>
峰值内存 = 检查点数 × 单层内存 + 最长重计算段的内存
</details>

<details>
<summary>答案</summary>

(a) k=5时：
- 检查点数：10个（每5层一个）
- 检查点内存：10 × 2GB = 20GB
- 最长段内存：5 × 2GB = 10GB
- 峰值内存：30GB

(b) k=10时：
- 检查点数：5个
- 每段重计算：最多9次前向传播
- 额外计算量：(9+8+7+...+1) × 5段 = 45 × 5 = 225次层计算
- 相对增加：225/50 = 4.5倍
</details>

**习题 8.3**：梯度量化误差
将梯度从FP32量化到INT8，梯度值范围为[-0.01, 0.01]。计算：
(a) 量化精度（最小可表示的梯度差）
(b) 当梯度值为0.0001时的相对误差上界

<details>
<summary>提示 (Hint)</summary>
INT8范围是-128到127，共256个值。量化步长 = (max-min)/255
</details>

<details>
<summary>答案</summary>

(a) 量化精度：
- 范围：0.01 - (-0.01) = 0.02
- 量化步长：0.02/255 ≈ 7.84×10^-5

(b) 相对误差：
- 绝对误差上界：7.84×10^-5 / 2 ≈ 3.92×10^-5
- 相对误差：3.92×10^-5 / 0.0001 = 39.2%
</details>

### 挑战题

**习题 8.4**：混合模式自动微分设计
设计一个算法，自动决定计算图中每个子图应该使用前向模式还是反向模式。考虑一个包含分支和汇聚的计算图：

```
输入x(100维) → 层A(100→500) → 分支
                              ├→ 层B(500→10) → 输出y1
                              └→ 层C(500→20) → 输出y2
```

<details>
<summary>提示 (Hint)</summary>
考虑扇入扇出比例，以及需要计算的雅可比矩阵部分。
</details>

<details>
<summary>答案</summary>

算法设计：
1. 计算每个节点的扇入扇出比：fan_ratio = out_dim / in_dim
2. 如果fan_ratio > 1，倾向使用反向模式
3. 如果fan_ratio < 1，倾向使用前向模式

对于给定图：
- 层A：500/100 = 5 → 反向模式
- 层B：10/500 = 0.02 → 前向模式
- 层C：20/500 = 0.04 → 前向模式

最优策略：
- 对整体使用反向模式计算∂L/∂A_output
- 对分支B和C各自使用前向模式传播到输出
</details>

**习题 8.5**：动态检查点优化
设计一个在线算法，根据运行时内存压力动态调整检查点。给定：
- 总内存：32GB
- 当前使用：24GB
- 网络深度：100层
- 每层激活值：0.5GB

<details>
<summary>提示 (Hint)</summary>
使用二分搜索找到最优检查点间隔，考虑内存安全边界。
</details>

<details>
<summary>答案</summary>

动态调整算法：
1. 计算可用内存：32 - 24 = 8GB
2. 安全边界：保留20%，实际可用 = 6.4GB
3. 二分搜索最优间隔k：
   - 检查点内存：(100/k) × 0.5GB
   - 重计算段内存：k × 0.5GB
   - 总需求：(100/k + k) × 0.5GB ≤ 6.4GB
4. 求解：k ≈ 11（检查点数≈9）
5. 实时监控并调整：
   - 如果内存压力增加，增大k
   - 如果内存压力减少，减小k以减少重计算
</details>

**习题 8.6**：高阶导数内存估算
对于一个包含n个参数的模型，估算计算k阶导数所需的内存。假设：
- 每个中间变量占用与参数相同的内存
- 计算图不进行优化

<details>
<summary>提示 (Hint)</summary>
考虑每阶导数会引入新的中间变量，数量呈指数增长。
</details>

<details>
<summary>答案</summary>

内存增长分析：
- 0阶（原函数）：O(n)
- 1阶导数：每个参数产生n个偏导数，O(n²)
- 2阶导数：每个一阶导数再产生n个偏导数，O(n³)
- k阶导数：O(n^(k+1))

优化策略：
1. 稀疏性利用：多数高阶偏导为0
2. 对称性利用：混合偏导的对称性
3. 选择性计算：只计算需要的部分
4. 实际内存需求：O(k × n²)（利用优化后）
</details>

**习题 8.7**：梯度压缩与收敛性
分析Top-K梯度稀疏化对SGD收敛性的影响。给定：
- 参数维度：10^6
- 稀疏率：K/N = 0.01
- 原始收敛率：O(1/√T)

<details>
<summary>提示 (Hint)</summary>
考虑稀疏化引入的偏差和方差，使用收敛性分析框架。
</details>

<details>
<summary>答案</summary>

收敛性分析：
1. 稀疏化引入的偏差：
   - E[g_sparse] ≠ E[g_true]
   - 偏差界：||bias|| ≤ (1-K/N) × ||g||

2. 额外方差：
   - Var[g_sparse] = Var[g] + σ²_sparse
   - σ²_sparse ∝ (1-K/N)

3. 修正的收敛率：
   - 原始：E[f(x_T) - f*] ≤ O(1/√T)
   - 稀疏化后：E[f(x_T) - f*] ≤ O(1/√T) + O((1-K/N))
   
4. 补偿策略：
   - 误差反馈：累积丢弃的梯度
   - 动态K值：随训练进展增加K
   - 最终收敛率可恢复到O(1/√T)
</details>

## 8.8 常见陷阱与错误 (Gotchas)

### 8.8.1 数值精度陷阱

**问题**：梯度消失或爆炸
- 症状：训练loss变为NaN或停止下降
- 原因：深层网络的链式法则导致梯度指数级变化
- 解决：梯度裁剪、批归一化、残差连接

**问题**：混合精度训练的下溢
- 症状：FP16训练时梯度变为0
- 原因：FP16表示范围有限（最小正数约6×10^-8）
- 解决：动态损失缩放、自动混合精度(AMP)

### 8.8.2 内存管理陷阱

**问题**：激活值内存泄漏
- 症状：训练过程中内存持续增长
- 原因：计算图保留了不必要的中间结果
- 解决：及时释放不需要的张量、使用no_grad上下文

**问题**：检查点策略不当
- 症状：内存未减少或训练极慢
- 原因：检查点过多（慢）或过少（内存大）
- 解决：使用自适应检查点算法

### 8.8.3 性能优化陷阱

**问题**：不必要的同步
- 症状：GPU利用率低，存在等待
- 原因：梯度all-reduce的同步点过多
- 解决：梯度累积、异步通信

**问题**：动态图重复构建
- 症状：每次迭代都重新构建计算图
- 原因：动态形状或控制流
- 解决：图缓存、静态子图提取

### 8.8.4 正确性陷阱

**问题**：梯度计算不正确
- 症状：优化不收敛或结果错误
- 原因：自定义算子的梯度实现错误
- 解决：数值微分验证、梯度检查

**问题**：非确定性行为
- 症状：相同输入产生不同梯度
- 原因：并行reduction的顺序不确定
- 解决：确定性算法选项、固定随机种子

## 8.9 最佳实践检查清单

### 设计阶段
- [ ] 确定前向/反向模式的选择策略
- [ ] 评估内存需求和检查点策略
- [ ] 设计梯度累积和通信方案
- [ ] 规划混合精度训练策略

### 实现阶段
- [ ] 实现梯度检查机制
- [ ] 添加数值稳定性保护（梯度裁剪、归一化）
- [ ] 实现内存监控和自适应策略
- [ ] 优化算子融合减少内存占用

### 验证阶段
- [ ] 使用数值微分验证梯度正确性
- [ ] 测试不同批大小下的数值稳定性
- [ ] 验证检查点恢复的正确性
- [ ] 基准测试内存和计算开销

### 优化阶段
- [ ] 分析内存瓶颈并优化
- [ ] 实现梯度压缩减少通信
- [ ] 优化高阶导数的计算路径
- [ ] 调优混合精度的缩放因子

### 部署阶段
- [ ] 确保跨平台数值一致性
- [ ] 实现故障恢复机制
- [ ] 监控训练稳定性指标
- [ ] 记录性能基准和瓶颈

---

*下一章：[第 9 章：并行化策略](chapter9.md)*