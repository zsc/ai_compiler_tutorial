<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第 16 章：NUMA 架构优化（二）</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">AI 编译器教程：从理论到 200T 规模实践</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 1 章：AI 编译器概述</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 2 章：中间表示（IR）设计</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 3 章：计算图表示与分析</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 4 章：统一缓冲区设计</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 5 章：内存规划与分配</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章：数据布局优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章：算子融合</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 8 章：自动微分与梯度优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 9 章：并行化策略</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章：多维 Stride DMA 利用</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 12 章：JIT 编译技术</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 13 章：GPU 编译优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 14 章：移动端与边缘设备优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 15 章：NUMA 架构优化（一）</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 16 章：NUMA 架构优化（二）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter17.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 17 章：动态 Shape 编译（一）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter18.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 18 章：动态 Shape 编译（二）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter19.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 19 章：稀疏与变长数据支持</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter20.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 20 章：JIT 编译技术</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter21.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 21 章：高维张量别名分析</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter22.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 22 章：投机执行支持</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter23.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 23 章：自动驾驶场景优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter24.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 24 章：具身智能编译挑战</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter25.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 25 章：200T 模型编译实践</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="16-numa">第 16 章：NUMA 架构优化（二）</h1>
<p>本章深入探讨 NUMA 架构下的高级优化技术，重点关注跨 Socket 通信优化、NUMA 平衡算法、大规模 Transformer 模型的 NUMA 适配，以及性能分析调优方法。通过本章学习，读者将掌握在多 Socket 系统上部署 200T 规模模型的关键技术，理解如何最小化远程内存访问开销，实现近线性的扩展性。</p>
<h2 id="161-socket">16.1 跨 Socket 通信优化</h2>
<h3 id="1611">16.1.1 通信拓扑分析</h3>
<p>在 NUMA 系统中，跨 Socket 通信的拓扑结构直接影响性能。现代服务器通常采用以下几种互联方式：</p>
<div class="codehilite"><pre><span></span><code><span class="mf">2</span><span class="o">-</span><span class="n">Socket</span><span class="w"> </span><span class="n">全连接</span><span class="p">:</span>
<span class="err">┌─────────┐</span><span class="w">  </span><span class="n">QPI</span><span class="o">/</span><span class="n">UPI</span><span class="w">  </span><span class="err">┌─────────┐</span>
<span class="err">│</span><span class="w"> </span><span class="n">Socket0</span><span class="w"> </span><span class="err">│◄──────────►│</span><span class="w"> </span><span class="n">Socket1</span><span class="w"> </span><span class="err">│</span>
<span class="err">└─────────┘</span><span class="w">            </span><span class="err">└─────────┘</span>

<span class="mf">4</span><span class="o">-</span><span class="n">Socket</span><span class="w"> </span><span class="n">全互联</span><span class="p">:</span>
<span class="err">┌─────────┐</span><span class="w">            </span><span class="err">┌─────────┐</span>
<span class="err">│</span><span class="w"> </span><span class="n">Socket0</span><span class="w"> </span><span class="err">│◄──────────►│</span><span class="w"> </span><span class="n">Socket1</span><span class="w"> </span><span class="err">│</span>
<span class="err">└────┬────┘</span><span class="w">            </span><span class="err">└────┬────┘</span>
<span class="w">     </span><span class="err">│</span><span class="w">      </span><span class="err">╲</span><span class="w">        </span><span class="err">╱</span><span class="w">      </span><span class="err">│</span>
<span class="w">     </span><span class="err">│</span><span class="w">        </span><span class="err">╲</span><span class="w">    </span><span class="err">╱</span><span class="w">        </span><span class="err">│</span>
<span class="w">     </span><span class="err">│</span><span class="w">          </span><span class="err">╳</span><span class="w">           </span><span class="err">│</span>
<span class="w">     </span><span class="err">│</span><span class="w">        </span><span class="err">╱</span><span class="w">    </span><span class="err">╲</span><span class="w">        </span><span class="err">│</span>
<span class="w">     </span><span class="err">│</span><span class="w">      </span><span class="err">╱</span><span class="w">        </span><span class="err">╲</span><span class="w">      </span><span class="err">│</span>
<span class="err">┌────▼────┐</span><span class="w">            </span><span class="err">┌────▼────┐</span>
<span class="err">│</span><span class="w"> </span><span class="n">Socket2</span><span class="w"> </span><span class="err">│◄──────────►│</span><span class="w"> </span><span class="n">Socket3</span><span class="w"> </span><span class="err">│</span>
<span class="err">└─────────┘</span><span class="w">            </span><span class="err">└─────────┘</span>

<span class="mf">8</span><span class="o">-</span><span class="n">Socket</span><span class="w"> </span><span class="n">立方体拓扑</span><span class="p">:</span>
<span class="w">         </span><span class="err">┌───────┐</span>
<span class="w">     </span><span class="err">┌───│</span><span class="w"> </span><span class="n">S4</span><span class="w">    </span><span class="err">│───┐</span>
<span class="w">     </span><span class="err">│</span><span class="w">   </span><span class="err">└───┬───┘</span><span class="w">   </span><span class="err">│</span>
<span class="w"> </span><span class="err">┌───▼───┐</span><span class="w">   </span><span class="err">│</span><span class="w">   </span><span class="err">┌───▼───┐</span>
<span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="n">S0</span><span class="w">    </span><span class="err">│───┼───│</span><span class="w"> </span><span class="n">S5</span><span class="w">    </span><span class="err">│</span>
<span class="w"> </span><span class="err">└───┬───┘</span><span class="w">   </span><span class="err">│</span><span class="w">   </span><span class="err">└───┬───┘</span>
<span class="w">     </span><span class="err">│</span><span class="w">   </span><span class="err">┌───▼───┐</span><span class="w">   </span><span class="err">│</span>
<span class="w">     </span><span class="err">└───│</span><span class="w"> </span><span class="n">S1</span><span class="w">    </span><span class="err">│───┘</span>
<span class="w">         </span><span class="err">└───┬───┘</span>
<span class="w">             </span><span class="err">│</span>
<span class="w">    </span><span class="err">[</span><span class="n">S2</span><span class="p">,</span><span class="n">S3</span><span class="p">,</span><span class="n">S6</span><span class="p">,</span><span class="n">S7</span><span class="w"> </span><span class="n">类似连接</span><span class="err">]</span>
</code></pre></div>

<p>通信延迟矩阵可表示为：</p>
<p>$$L_{ij} = \begin{cases}
L_{local} &amp; \text{if } i = j \\
L_{1hop} &amp; \text{if 直接连接} \\
L_{2hop} &amp; \text{if 需要一次中转} \\
L_{nhop} &amp; \text{if 需要 n-1 次中转}
\end{cases}$$
其中典型值为：</p>
<ul>
<li>$L_{local} \approx 10ns$（本地内存访问）</li>
<li>$L_{1hop} \approx 20-30ns$（直连 Socket）</li>
<li>$L_{2hop} \approx 40-50ns$（一次中转）</li>
</ul>
<h3 id="1612">16.1.2 通信模式优化</h3>
<h4 id="_1">点对点通信优化</h4>
<p>对于大规模张量传输，采用分块流水线策略：
$$T_{total} = \max(T_{split}, T_{transfer}, T_{merge})$$
其中：</p>
<ul>
<li>$T_{split}$：数据切分时间</li>
<li>$T_{transfer}$：传输时间，$T_{transfer} = \frac{S}{B_{inter}} + L_{ij}$</li>
<li>$T_{merge}$：数据合并时间</li>
</ul>
<p>优化策略：</p>
<ol>
<li><strong>双缓冲机制</strong>：传输与计算重叠</li>
<li><strong>NUMA 感知的数据分块</strong>：块大小适配 LLC 容量</li>
<li><strong>传输聚合</strong>：小消息合并减少开销</li>
</ol>
<h4 id="_2">集合通信优化</h4>
<p>All-Reduce 操作的 NUMA 优化：</p>
<div class="codehilite"><pre><span></span><code>Ring All-Reduce with NUMA awareness:
Step 1: Intra-Socket Reduce
  Socket0: GPU0,1,2,3 → Local Reduce
  Socket1: GPU4,5,6,7 → Local Reduce

Step 2: Inter-Socket Exchange
  Socket0 ←→ Socket1 (仅交换一次)

Step 3: Intra-Socket Broadcast
  Socket0: Broadcast to GPU0,1,2,3
  Socket1: Broadcast to GPU4,5,6,7
</code></pre></div>

<p>通信复杂度分析：
$$T_{allreduce} = 2 \cdot \frac{(p-1) \cdot S}{p \cdot B_{intra}} + \frac{S}{B_{inter}}$$
其中：</p>
<ul>
<li>$p$：每个 Socket 内的 GPU 数量</li>
<li>$S$：数据大小</li>
<li>$B_{intra}$：Socket 内带宽</li>
<li>$B_{inter}$：Socket 间带宽</li>
</ul>
<h3 id="1613">16.1.3 内存一致性协议优化</h3>
<p>NUMA 系统的缓存一致性协议（如 MESIF）开销分析：</p>
<p>状态转换成本矩阵：
$$C_{transition} = \begin{bmatrix}
0 &amp; C_{M→E} &amp; C_{M→S} &amp; C_{M→I} &amp; C_{M→F} \\
C_{E→M} &amp; 0 &amp; C_{E→S} &amp; C_{E→I} &amp; C_{E→F} \\
C_{S→M} &amp; C_{S→E} &amp; 0 &amp; C_{S→I} &amp; C_{S→F} \\
C_{I→M} &amp; C_{I→E} &amp; C_{I→S} &amp; 0 &amp; C_{I→F} \\
C_{F→M} &amp; C_{F→E} &amp; C_{F→S} &amp; C_{F→I} &amp; 0
\end{bmatrix}$$
优化原则：</p>
<ol>
<li><strong>减少 False Sharing</strong>：对齐到缓存行边界</li>
<li><strong>批量更新</strong>：减少一致性协议触发次数</li>
<li><strong>只读数据复制</strong>：利用 F 状态避免回写</li>
</ol>
<h2 id="162-numa">16.2 NUMA 平衡算法</h2>
<h3 id="1621">16.2.1 静态负载平衡</h3>
<p>基于图分割的 NUMA 平衡算法：</p>
<p>给定计算图 $\mathcal{G} = (V, E)$，目标是找到 k-way 分割 $\Pi = \{V_1, V_2, ..., V_k\}$，最小化：
$$\min_{\Pi} \sum_{e=(u,v) \in E_{cut}} w(e) + \lambda \cdot \max_{i} \left(\sum_{v \in V_i} c(v)\right)$$
其中：</p>
<ul>
<li>$E_{cut}$：跨分区边集</li>
<li>$w(e)$：边权重（通信量）</li>
<li>$c(v)$：节点计算成本</li>
<li>$\lambda$：平衡因子</li>
</ul>
<p>使用多级图分割算法：</p>
<ol>
<li><strong>粗化阶段</strong>：合并相似节点</li>
<li><strong>初始分割</strong>：谱聚类或 METIS</li>
<li><strong>细化阶段</strong>：KL/FM 算法优化</li>
</ol>
<h3 id="1622">16.2.2 动态负载迁移</h3>
<p>运行时页面迁移策略：
$$M_{score}(p, n) = \alpha \cdot A_{local}(p, n) - \beta \cdot A_{remote}(p, n) - \gamma \cdot C_{migrate}$$
其中：</p>
<ul>
<li>$A_{local}(p, n)$：页面 p 在节点 n 的本地访问频率</li>
<li>$A_{remote}(p, n)$：远程访问频率</li>
<li>$C_{migrate}$：迁移成本</li>
</ul>
<p>迁移决策阈值：
$$\text{Migrate if } M_{score}(p, n_{target}) - M_{score}(p, n_{current}) &gt; \theta$$</p>
<h3 id="1623">16.2.3 自适应调度算法</h3>
<p>基于强化学习的 NUMA 调度器：</p>
<p>状态空间 $\mathcal{S}$：</p>
<ul>
<li>各节点内存使用率：$\{m_1, m_2, ..., m_k\}$</li>
<li>跨节点通信矩阵：$\mathbf{C} \in \mathbb{R}^{k \times k}$</li>
<li>任务队列长度：$\{q_1, q_2, ..., q_k\}$</li>
</ul>
<p>动作空间 $\mathcal{A}$：</p>
<ul>
<li>任务分配：$a_{task} \in \{1, 2, ..., k\}$</li>
<li>数据放置：$a_{data} \in \{1, 2, ..., k\}$</li>
</ul>
<p>奖励函数：
$$R = -\left(T_{exec} + \alpha \cdot T_{comm} + \beta \cdot \text{Imbalance}\right)$$</p>
<h2 id="163-transformer-numa">16.3 大规模 Transformer 的 NUMA 优化</h2>
<h3 id="1631-numa">16.3.1 注意力机制的 NUMA 分解</h3>
<p>对于序列长度 $L$、隐藏维度 $d$、头数 $h$ 的多头注意力：
$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$
NUMA 分解策略：</p>
<ol>
<li>
<p><strong>序列维度分割</strong>：
   - Socket $i$ 处理序列片段 $[L_i, L_{i+1})$
   - 通信量：$O(h \cdot d \cdot L)$</p>
</li>
<li>
<p><strong>注意力头分割</strong>：
   - Socket $i$ 处理头 $[h_i, h_{i+1})$
   - 通信量：$O(L^2)$（仅 softmax 归一化）</p>
</li>
<li>
<p><strong>混合分割</strong>：
$$\text{Socket}(i,j) = \text{Heads}[ih:ih+\Delta h] \times \text{Seq}[jL:jL+\Delta L]$$
内存访问模式优化：</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code>Blocked Attention Computation:
┌────────────────────────┐
│  Q blocks (Socket 0)   │
├────┬────┬────┬────────┤
│ B00│ B01│ B02│  ...   │
├────┼────┼────┼────────┤
│ K,V blocks distributed │
│   across Sockets       │
└────────────────────────┘
</code></pre></div>

<h3 id="1632-ffn-numa">16.3.2 FFN 层的 NUMA 优化</h3>
<p>前馈网络层：
$$\text{FFN}(x) = \text{GELU}(xW_1 + b_1)W_2 + b_2$$
其中 $W_1 \in \mathbb{R}^{d \times 4d}$，$W_2 \in \mathbb{R}^{4d \times d}$</p>
<p>优化策略：</p>
<ol>
<li>
<p><strong>列并行分割</strong> $W_1$：
$$W_1 = [W_1^{(0)} | W_1^{(1)} | ... | W_1^{(k-1)}]$$
每个 Socket 计算部分激活</p>
</li>
<li>
<p><strong>行并行分割</strong> $W_2$：
$$W_2 = \begin{bmatrix} W_2^{(0)} \\ W_2^{(1)} \\ \vdots \\ W_2^{(k-1)} \end{bmatrix}$$
需要 All-Reduce 合并结果</p>
</li>
</ol>
<p>通信成本分析：</p>
<ul>
<li>列并行：无通信（计算独立）</li>
<li>行并行：$O(batch \times seq \times d)$ 的 All-Reduce</li>
</ul>
<h3 id="1633-kv-cache-numa">16.3.3 KV Cache 的 NUMA 管理</h3>
<p>对于长序列生成任务，KV Cache 的 NUMA 布局至关重要：</p>
<p>内存占用：
$$M_{KV} = 2 \times layers \times heads \times seq_len \times d_k \times batch$$
分布式 KV Cache 设计：</p>
<div class="codehilite"><pre><span></span><code><span class="n">NUMA</span><span class="o">-</span><span class="n">aware</span><span class="w"> </span><span class="n">KV</span><span class="w"> </span><span class="n">Cache</span><span class="w"> </span><span class="n">Layout</span><span class="o">:</span>
<span class="err">┌─────────────────────────────┐</span>
<span class="err">│</span><span class="w"> </span><span class="n">Socket</span><span class="w"> </span><span class="mi">0</span><span class="o">:</span><span class="w"> </span><span class="n">Layers</span><span class="w"> </span><span class="mi">0-15</span><span class="w">       </span><span class="err">│</span>
<span class="err">│</span><span class="w"> </span><span class="err">┌─────────┬───────────────┐</span><span class="w"> </span><span class="err">│</span>
<span class="err">│</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="n">K</span><span class="o">-</span><span class="n">Cache</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="n">Head</span><span class="w"> </span><span class="mi">0-3</span><span class="w">      </span><span class="err">│</span><span class="w"> </span><span class="err">│</span>
<span class="err">│</span><span class="w"> </span><span class="err">├─────────┼───────────────┤</span><span class="w"> </span><span class="err">│</span>
<span class="err">│</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="n">V</span><span class="o">-</span><span class="n">Cache</span><span class="w"> </span><span class="err">│</span><span class="w"> </span><span class="n">Head</span><span class="w"> </span><span class="mi">0-3</span><span class="w">      </span><span class="err">│</span><span class="w"> </span><span class="err">│</span>
<span class="err">│</span><span class="w"> </span><span class="err">└─────────┴───────────────┘</span><span class="w"> </span><span class="err">│</span>
<span class="err">├─────────────────────────────┤</span>
<span class="err">│</span><span class="w"> </span><span class="n">Socket</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="w"> </span><span class="n">Layers</span><span class="w"> </span><span class="mi">16-31</span><span class="w">      </span><span class="err">│</span>
<span class="err">│</span><span class="w"> </span><span class="p">[</span><span class="n">Similar</span><span class="w"> </span><span class="n">structure</span><span class="p">]</span><span class="w">         </span><span class="err">│</span>
<span class="err">└─────────────────────────────┘</span>
</code></pre></div>

<p>访问模式优化：</p>
<ol>
<li><strong>预取策略</strong>：基于生成位置的预测性预取</li>
<li><strong>层间复用</strong>：相邻层共享 Socket 减少迁移</li>
<li><strong>压缩存储</strong>：量化 + 稀疏表示降低带宽需求</li>
</ol>
<h3 id="1634-pipeline-numa">16.3.4 Pipeline 并行的 NUMA 适配</h3>
<p>流水线并行中的 NUMA 感知调度：
$$\text{Stage}_{assignment} = \arg\min_{S} \left( T_{compute}^{max} + T_{comm}^{total} \right)$$
约束条件：</p>
<ul>
<li>内存约束：$\sum_{s \in S_i} M(s) \leq M_{node_i}$</li>
<li>带宽约束：$B_{used} \leq B_{available}$</li>
</ul>
<p>优化的微批次调度：</p>
<div class="codehilite"><pre><span></span><code><span class="mf">1</span><span class="n">F1B</span><span class="w"> </span><span class="n">Schedule</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">NUMA</span><span class="p">:</span>
<span class="n">Time</span><span class="w"> </span><span class="err">→</span>
<span class="n">Socket0</span><span class="p">:</span><span class="w"> </span><span class="n">F0</span><span class="w"> </span><span class="n">F1</span><span class="w"> </span><span class="n">F2</span><span class="w"> </span><span class="n">F3</span><span class="w"> </span><span class="n">B3</span><span class="w"> </span><span class="n">B2</span><span class="w"> </span><span class="n">B1</span><span class="w"> </span><span class="n">B0</span><span class="w"> </span><span class="n">F4</span><span class="w"> </span><span class="n">F5</span><span class="mf">...</span>
<span class="n">Socket1</span><span class="p">:</span><span class="w">    </span><span class="n">F0</span><span class="w"> </span><span class="n">F1</span><span class="w"> </span><span class="n">F2</span><span class="w"> </span><span class="n">F3</span><span class="w"> </span><span class="n">B3</span><span class="w"> </span><span class="n">B2</span><span class="w"> </span><span class="n">B1</span><span class="w"> </span><span class="n">B0</span><span class="w"> </span><span class="n">F4</span><span class="mf">...</span>
<span class="n">Socket2</span><span class="p">:</span><span class="w">       </span><span class="n">F0</span><span class="w"> </span><span class="n">F1</span><span class="w"> </span><span class="n">F2</span><span class="w"> </span><span class="n">F3</span><span class="w"> </span><span class="n">B3</span><span class="w"> </span><span class="n">B2</span><span class="w"> </span><span class="n">B1</span><span class="w"> </span><span class="n">B0</span><span class="mf">...</span>
<span class="n">Socket3</span><span class="p">:</span><span class="w">          </span><span class="n">F0</span><span class="w"> </span><span class="n">F1</span><span class="w"> </span><span class="n">F2</span><span class="w"> </span><span class="n">F3</span><span class="w"> </span><span class="n">B3</span><span class="w"> </span><span class="n">B2</span><span class="w"> </span><span class="n">B1</span><span class="mf">...</span>

<span class="n">F</span><span class="o">=</span><span class="kr">For</span><span class="n">ward</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="o">=</span><span class="n">Backward</span>
<span class="n">数字表示微批次编号</span>
</code></pre></div>

<h2 id="164">16.4 性能分析与调优</h2>
<h3 id="1641">16.4.1 性能指标体系</h3>
<p>NUMA 性能指标层次：</p>
<ol>
<li>
<p><strong>硬件层指标</strong>：
   - 本地/远程内存访问比：$R_{L/R} = \frac{N_{local}}{N_{remote}}$
   - QPI/UPI 利用率：$U_{link} = \frac{B_{actual}}{B_{theoretical}}$
   - 内存控制器饱和度：$S_{MC} = \frac{Requests_{actual}}{Requests_{max}}$</p>
</li>
<li>
<p><strong>系统层指标</strong>：
   - NUMA 节点负载均衡度：$B_{load} = 1 - \frac{\sigma(Load_i)}{\mu(Load_i)}$
   - 页面迁移频率：$F_{migrate} = \frac{Pages_{migrated}}{Time}$
   - 缓存一致性开销：$O_{coherence} = \frac{T_{coherence}}{T_{total}}$</p>
</li>
<li>
<p><strong>应用层指标</strong>：
   - 计算通信比：$\rho = \frac{T_{compute}}{T_{communication}}$
   - 并行效率：$E = \frac{Speedup}{N_{sockets}}$
   - 内存带宽效率：$\eta_{mem} = \frac{BW_{achieved}}{BW_{peak} \times N_{sockets}}$</p>
</li>
</ol>
<h3 id="1642">16.4.2 性能分析工具</h3>
<p>使用 PMU 计数器进行细粒度分析：</p>
<div class="codehilite"><pre><span></span><code>关键性能事件：

<span class="k">-</span> UNC_M_CAS_COUNT.RD: 内存读请求
<span class="k">-</span> UNC_M_CAS_COUNT.WR: 内存写请求  
<span class="k">-</span> UNC_Q_RxL_FLITS: QPI/UPI 流量
<span class="k">-</span> OFFCORE_RESPONSE: 远程内存访问
</code></pre></div>

<p>性能瓶颈识别决策树：</p>
<div class="codehilite"><pre><span></span><code>                高延迟？
                   │
         ┌─────────┴─────────┐
         │                   │
         是                  否
         │                   │
    远程访问多？          带宽饱和？
         │                   │
    ┌────┴────┐         ┌────┴────┐
    是        否        是        否
    │         │         │         │
数据布局  缓存竞争  通信优化  计算优化
</code></pre></div>

<h3 id="1643">16.4.3 调优策略矩阵</h3>
<p>基于 Roofline 模型的 NUMA 调优：
$$P = \min\left(P_{peak}, I \times BW_{effective}\right)$$
其中有效带宽考虑 NUMA 因素：
$$BW_{effective} = \alpha \cdot BW_{local} + (1-\alpha) \cdot BW_{remote}$$
$\alpha$ 是本地访问比例。</p>
<p>调优决策表：</p>
<p>| 算术强度 | NUMA 比例 | 优化策略 |</p>
<table>
<thead>
<tr>
<th>算术强度</th>
<th>NUMA 比例</th>
<th>优化策略</th>
</tr>
</thead>
<tbody>
<tr>
<td>低 (&lt;0.5)</td>
<td>高远程</td>
<td>数据重分布</td>
</tr>
<tr>
<td>低 (&lt;0.5)</td>
<td>高本地</td>
<td>预取优化</td>
</tr>
<tr>
<td>中 (0.5-4)</td>
<td>高远程</td>
<td>计算迁移</td>
</tr>
<tr>
<td>中 (0.5-4)</td>
<td>高本地</td>
<td>向量化</td>
</tr>
<tr>
<td>高 (&gt;4)</td>
<td>任意</td>
<td>计算优化</td>
</tr>
</tbody>
</table>
<h3 id="1644-200t-numa">16.4.4 案例：200T 模型的 NUMA 调优</h3>
<p>实际 200T 参数模型在 8-Socket 系统上的优化过程：</p>
<p><strong>初始性能分析</strong>：</p>
<ul>
<li>远程内存访问：45%</li>
<li>QPI 带宽利用率：78%</li>
<li>并行效率：4.2/8 = 52.5%</li>
</ul>
<p><strong>优化步骤</strong>：</p>
<ol>
<li>
<p><strong>重新设计数据布局</strong>：
   - 权重矩阵按 Socket 边界对齐
   - 激活张量采用 NUMA-aware allocation
   - 结果：远程访问降至 28%</p>
</li>
<li>
<p><strong>优化通信模式</strong>：
   - Ring AllReduce → Hierarchical AllReduce
   - 小消息聚合，批大小从 1MB → 16MB
   - 结果：QPI 利用率降至 65%</p>
</li>
<li>
<p><strong>调整并行策略</strong>：
   - 从纯数据并行改为混合并行
   - Pipeline stages 与 Socket 边界对齐
   - 结果：并行效率提升至 6.8/8 = 85%</p>
</li>
</ol>
<p><strong>最终性能提升</strong>：</p>
<ul>
<li>端到端吞吐量：2.4x</li>
<li>内存带宽利用率：82%</li>
<li>延迟降低：35%</li>
</ul>
<p>性能剖析对比：</p>
<div class="codehilite"><pre><span></span><code>优化前时间分布：          优化后时间分布：
┌───────────────┐        ┌───────────────┐
│ Compute: 45%  │        │ Compute: 68%  │
├───────────────┤        ├───────────────┤
│ Local Mem: 20%│        │ Local Mem: 22%│
├───────────────┤        ├───────────────┤
│ Remote Mem:25%│        │ Remote Mem: 7%│
├───────────────┤        ├───────────────┤
│ Sync: 10%     │        │ Sync: 3%      │
└───────────────┘        └───────────────┘
</code></pre></div>

<h2 id="_3">本章小结</h2>
<p>本章深入探讨了 NUMA 架构的高级优化技术，涵盖了从硬件层面的跨 Socket 通信优化到应用层面的大规模 Transformer 模型适配。核心要点包括：</p>
<ol>
<li>
<p><strong>跨 Socket 通信优化</strong>：理解不同拓扑结构的通信特性，采用分块流水线、双缓冲、NUMA 感知的集合通信等策略，显著降低远程访问开销。</p>
</li>
<li>
<p><strong>NUMA 平衡算法</strong>：通过静态图分割、动态页面迁移和自适应调度，实现计算和数据的最优分布，关键公式：
   - 迁移评分：$M_{score}(p, n) = \alpha \cdot A_{local} - \beta \cdot A_{remote} - \gamma \cdot C_{migrate}$
   - 图分割目标：$\min \sum_{e \in E_{cut}} w(e) + \lambda \cdot \max_i \sum_{v \in V_i} c(v)$</p>
</li>
<li>
<p><strong>Transformer NUMA 优化</strong>：针对注意力机制、FFN 层、KV Cache 的特点设计专门的 NUMA 分解策略，实现近线性扩展。</p>
</li>
<li>
<p><strong>性能分析与调优</strong>：建立多层次性能指标体系，使用 PMU 计数器精确定位瓶颈，通过实际案例展示 2.4x 的性能提升。</p>
</li>
</ol>
<p>关键性能公式汇总：</p>
<ul>
<li>有效带宽：$BW_{effective} = \alpha \cdot BW_{local} + (1-\alpha) \cdot BW_{remote}$</li>
<li>并行效率：$E = \frac{Speedup}{N_{sockets}}$</li>
<li>Roofline 性能：$P = \min(P_{peak}, I \times BW_{effective})$</li>
</ul>
<h2 id="_4">练习题</h2>
<h3 id="_5">基础题</h3>
<ol>
<li><strong>通信延迟计算</strong>
   在一个 4-Socket 全互联系统中，本地内存访问延迟为 10ns，直连 Socket 访问延迟为 25ns，需要一次中转的访问延迟为 45ns。如果一个应用有 60% 本地访问、30% 直连访问、10% 需要中转的访问，计算平均内存访问延迟。</li>
</ol>
<details markdown="block">
   <summary markdown="off">答案</summary>

   平均延迟 = 0.6 × 10 + 0.3 × 25 + 0.1 × 45 = 6 + 7.5 + 4.5 = 18ns

   相比纯本地访问，延迟增加了 80%，这说明 NUMA 优化的重要性。
   </details>
<ol start="2">
<li><strong>All-Reduce 通信量分析</strong>
   在 8 个 GPU（分布在 2 个 Socket，每个 4 GPU）的系统上执行 Ring All-Reduce，数据大小为 4GB。如果 Socket 内带宽为 200GB/s，Socket 间带宽为 50GB/s，计算 NUMA 感知的分层 All-Reduce 相比普通 Ring All-Reduce 的加速比。</li>
</ol>
<details markdown="block">
   <summary markdown="off">答案</summary>

   普通 Ring All-Reduce：

   - 总传输量：7 × 4GB = 28GB
   - 假设一半通过 Socket 间链路：14GB / 50GB/s = 0.28s

   NUMA 分层 All-Reduce：

   - Socket 内 Reduce：3 × 4GB / 200GB/s × 2 = 0.06s
   - Socket 间交换：4GB / 50GB/s = 0.08s  
   - Socket 内 Broadcast：3 × 4GB / 200GB/s × 2 = 0.06s
   - 总时间：max(0.06, 0.08, 0.06) = 0.08s（并行执行）

   加速比：0.28 / 0.08 = 3.5x
   </details>
<ol start="3">
<li><strong>内存带宽效率计算</strong>
   一个 NUMA 系统有 4 个节点，每个节点峰值带宽 100GB/s。测量得到本地访问带宽 90GB/s，远程访问带宽 30GB/s。如果应用的本地访问比例为 75%，计算内存带宽效率。</li>
</ol>
<details markdown="block">
   <summary markdown="off">答案</summary>

   有效带宽 = 0.75 × 90 + 0.25 × 30 = 67.5 + 7.5 = 75GB/s

   总峰值带宽 = 4 × 100 = 400GB/s
   实际总带宽 = 4 × 75 = 300GB/s（假设均衡负载）

   带宽效率 = 300 / 400 = 75%
   </details>
<h3 id="_6">挑战题</h3>
<ol start="4">
<li><strong>NUMA 感知的矩阵乘法分块</strong>
   设计一个 NUMA 感知的矩阵乘法 C = A × B 的分块策略，其中 A 是 M×K 矩阵，B 是 K×N 矩阵，系统有 P 个 NUMA 节点。要求最小化跨节点通信量，给出分块大小和数据分布方案。</li>
</ol>
<p><strong>Hint</strong>: 考虑 2D 分块和 Cannon 算法的 NUMA 适配。</p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   采用 2D 分块，将处理器组织为 √P × √P 网格：

   1. 分块大小：
      - A 分块：(M/√P) × K
      - B 分块：K × (N/√P)  
      - C 分块：(M/√P) × (N/√P)

   2. 初始数据分布：
      - 节点 (i,j) 持有 A[i,:] 和 B[:,j]

   3. 计算步骤（Cannon 算法）：
      - 初始对齐：A 的第 i 行循环左移 i 位，B 的第 j 列循环上移 j 位
      - √P 轮迭代，每轮：
        * 本地计算：C[i,j] += A[i,k] × B[k,j]
        * A 左移一位，B 上移一位

   4. 通信量分析：
      - 每个节点每轮发送：MK/P + KN/P
      - 总通信量：√P × (MK + KN) / √P = MK + KN
      - 相比朴素方法减少 √P 倍
   </details>
<ol start="5">
<li><strong>动态 NUMA 负载平衡算法</strong>
   设计一个基于工作窃取的 NUMA 感知调度器，考虑任务亲和性和数据局部性。给出窃取策略和性能模型。</li>
</ol>
<p><strong>Hint</strong>: 分层工作窃取，优先从同一 NUMA 节点窃取。</p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   分层工作窃取算法：

   1. 队列组织：
      - 每个核心维护本地队列
      - 每个 NUMA 节点维护共享队列
      - 全局队列作为最后手段

   2. 窃取优先级：
      - Level 0：本地队列（无开销）
      - Level 1：同一 NUMA 节点其他核心（低开销）
      - Level 2：直连 NUMA 节点（中等开销）
      - Level 3：远程 NUMA 节点（高开销）

   3. 窃取决策函数：
$$Steal(i,j) = \begin{cases}
      1 &amp; \text{if } Q\_j &gt; \theta\_1 \text{ and } d(i,j) = 0 \\\\
      p\_1 &amp; \text{if } Q\_j &gt; \theta\_2 \text{ and } d(i,j) = 1 \\\\
      p\_2 &amp; \text{if } Q\_j &gt; \theta\_3 \text{ and } d(i,j) = 2 \\\\
      0 &amp; \text{otherwise}
      \end{cases}$$

   4. 性能模型：
      - 负载不均衡成本：$C\_{imbalance} = \sigma(Q\_i) \times T\_{task}$
      - 窃取开销：$C\_{steal} = \sum\_{i,j} N\_{steal}(i,j) \times L\_{ij}$
      - 总成本：$C\_{total} = C\_{imbalance} + C\_{steal}$

   5. 自适应参数调整：
      - 监控窃取成功率
      - 动态调整阈值 θ 和概率 p
      - 使用指数加权移动平均平滑
   </details>
<ol start="6">
<li><strong>200T 模型的 NUMA 内存规划</strong>
   一个 200T 参数的 GPT 模型需要在 8-Socket 系统上部署，每个 Socket 有 1TB 内存。设计内存布局方案，考虑模型并行、数据并行和流水线并行的混合策略。</li>
</ol>
<p><strong>Hint</strong>: 考虑参数、激活、优化器状态和 KV Cache 的分布。</p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   内存规划方案：

   1. 内存需求分析（FP16 + 混合精度训练）：
      - 模型参数：200T × 2B = 400TB
      - 梯度：200T × 2B = 400TB  
      - 优化器状态（Adam）：200T × 8B = 1600TB
      - 激活值（seq=8K, batch=512）：约 100TB
      - KV Cache（生成）：约 50TB
      - 总需求：约 2550TB

   2. 并行策略（8 Sockets × 1TB = 8TB 可用）：
      - 模型并行度：MP = 64
      - 数据并行度：DP = 32  
      - 流水线并行度：PP = 8
      - 总并行度：64 × 32 × 8 = 16384

   3. Socket 级别分配：
      - 每个 Socket 负责 PP 的一个 stage
      - Stage 内部做 MP，每 Socket 8 个 MP 分片
      - 参数：400TB / 16384 ≈ 25GB per rank
      - 优化器：1600TB / 16384 ≈ 100GB per rank

   4. NUMA 优化布局：


<div class="codehilite"><pre><span></span><code>Socket 0-1: Layers 0-31 (Embedding + Early layers)
Socket 2-3: Layers 32-63 
Socket 4-5: Layers 64-95
Socket 6-7: Layers 96-127 (Output + Late layers)
</code></pre></div>



   5. 数据流优化：
      - Forward：Socket 0→1→...→7
      - Backward：Socket 7→6→...→0
      - 使用双缓冲隐藏通信延迟
      - 激活检查点存储在产生它的 Socket

   6. 内存复用策略：
      - 激活值在 backward 后立即释放
      - KV Cache 使用环形缓冲区
      - 优化器状态分片存储，按需换入
   </details>
<h2 id="gotchas">常见陷阱与错误 (Gotchas)</h2>
<ol>
<li>
<p><strong>False Sharing 导致的性能退化</strong>
   - 错误：多个线程更新同一缓存行的不同变量
   - 解决：使用 padding 对齐到缓存行边界（通常 64 字节）</p>
</li>
<li>
<p><strong>不当的内存分配策略</strong>
   - 错误：使用默认 malloc，导致页面分配到错误的 NUMA 节点
   - 解决：使用 numa_alloc_onnode 或设置内存策略</p>
</li>
<li>
<p><strong>忽视 NUMA 距离的影响</strong>
   - 错误：假设所有远程访问代价相同
   - 解决：查询 NUMA 距离矩阵，考虑多跳访问</p>
</li>
<li>
<p><strong>过度的页面迁移</strong>
   - 错误：频繁迁移页面导致开销超过收益
   - 解决：设置迁移阈值，使用迁移批处理</p>
</li>
<li>
<p><strong>线程绑定不当</strong>
   - 错误：线程在 NUMA 节点间迁移
   - 解决：使用 CPU affinity 绑定线程到特定核心</p>
</li>
<li>
<p><strong>忽略 QPI/UPI 带宽限制</strong>
   - 错误：过度依赖跨 Socket 通信
   - 解决：监控链路利用率，调整通信模式</p>
</li>
</ol>
<h2 id="_7">最佳实践检查清单</h2>
<h3 id="_8">设计阶段</h3>
<ul>
<li>[ ] 分析目标硬件的 NUMA 拓扑结构</li>
<li>[ ] 评估应用的内存访问模式和通信需求</li>
<li>[ ] 选择合适的并行策略（数据/模型/流水线）</li>
<li>[ ] 设计 NUMA 感知的数据结构和算法</li>
<li>[ ] 规划内存布局，最小化跨节点访问</li>
</ul>
<h3 id="_9">实现阶段</h3>
<ul>
<li>[ ] 使用 NUMA API 进行内存分配</li>
<li>[ ] 实现分层通信原语</li>
<li>[ ] 添加线程/进程绑定</li>
<li>[ ] 实现数据预取和缓存优化</li>
<li>[ ] 使用内存池减少分配开销</li>
</ul>
<h3 id="_10">调优阶段</h3>
<ul>
<li>[ ] 使用 PMU 计数器收集性能数据</li>
<li>[ ] 分析本地/远程访问比例</li>
<li>[ ] 监控 QPI/UPI 链路利用率</li>
<li>[ ] 评估负载均衡效果</li>
<li>[ ] 迭代优化热点代码路径</li>
</ul>
<h3 id="_11">验证阶段</h3>
<ul>
<li>[ ] 在不同 NUMA 配置下测试</li>
<li>[ ] 验证扩展性（weak/strong scaling）</li>
<li>[ ] 检查内存泄漏和碎片化</li>
<li>[ ] 确认性能指标达到预期</li>
<li>[ ] 文档化 NUMA 相关配置要求</li>
</ul>
            </article>
            
            <nav class="page-nav"><a href="chapter15.html" class="nav-link prev">← 第 15 章：NUMA 架构优化（一）</a><a href="chapter17.html" class="nav-link next">第 17 章：动态 Shape 编译（一） →</a></nav>
        </main>
    </div>
</body>
</html>