<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第 7 章：算子融合</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">AI 编译器教程：从理论到 200T 规模实践</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 1 章：AI 编译器概述</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 2 章：中间表示（IR）设计</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 3 章：计算图表示与分析</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 4 章：统一缓冲区设计</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 5 章：内存规划与分配</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章：数据布局优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章：算子融合</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 8 章：自动微分与梯度优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 9 章：并行化策略</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章：多维 Stride DMA 利用</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 12 章：JIT 编译技术</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 13 章：GPU 编译优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 14 章：移动端与边缘设备优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 15 章：NUMA 架构优化（一）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 16 章：NUMA 架构优化（二）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter17.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 17 章：动态 Shape 编译（一）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter18.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 18 章：动态 Shape 编译（二）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter19.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 19 章：稀疏与变长数据支持</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter20.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 20 章：JIT 编译技术</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter21.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 21 章：高维张量别名分析</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter22.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 22 章：投机执行支持</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter23.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 23 章：自动驾驶场景优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter24.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 24 章：具身智能编译挑战</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter25.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 25 章：200T 模型编译实践</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="7">第 7 章：算子融合</h1>
<p>算子融合是 AI 编译器优化的核心技术之一，通过将多个细粒度算子合并为单个粗粒度算子，显著减少内存访问开销和核函数启动开销。在自动驾驶和具身智能等对延迟敏感的场景中，算子融合可以将推理延迟降低 30-50%，同时减少内存带宽压力。本章将深入探讨算子融合的理论基础、实现策略和性能分析模型。</p>
<h2 id="71">7.1 垂直融合与水平融合</h2>
<p>算子融合可以从两个维度进行分类：垂直融合关注生产者-消费者关系的算子链，水平融合则并行合并独立的算子。理解这两种融合模式的特点和适用场景是设计高效融合策略的基础。</p>
<h3 id="711-producer-consumer-fusion">7.1.1 垂直融合（Producer-Consumer Fusion）</h3>
<p>垂直融合将具有生产者-消费者关系的算子序列合并为单个算子。考虑计算图中的算子链：</p>
<p>$$
y = \phi_n(\phi_{n-1}(...\phi_2(\phi_1(x))))
$$</p>
<p>其中每个 $\phi_i$ 代表一个算子变换。未融合时，中间结果需要写入和读取全局内存：</p>
<div class="codehilite"><pre><span></span><code>算子链执行流程（未融合）：
    x → [全局内存] → φ₁ → [全局内存] → φ₂ → ... → φₙ → y

    内存访问次数：2n 次（n次读 + n次写）
    核函数启动：n 次
</code></pre></div>

<p>融合后的执行流程：</p>
<div class="codehilite"><pre><span></span><code>算子链执行流程（融合后）：
    x → [寄存器/共享内存] → φ₁∘φ₂∘...∘φₙ → y

    内存访问次数：2 次（1次读 + 1次写）
    核函数启动：1 次
</code></pre></div>

<p><strong>融合收益分析</strong>：</p>
<p>设输入张量大小为 $N$，每个元素占用 $b$ 字节，内存带宽为 $B$，则：</p>
<ul>
<li>未融合的内存传输时间：$T_{unfused} = \frac{2nNb}{B}$</li>
<li>融合后的内存传输时间：$T_{fused} = \frac{2Nb}{B}$</li>
<li>加速比：$S = \frac{T_{unfused}}{T_{fused}} = n$</li>
</ul>
<h3 id="712-parallel-fusion">7.1.2 水平融合（Parallel Fusion）</h3>
<p>水平融合将多个独立的算子并行执行，共享输入数据的内存读取：</p>
<div class="codehilite"><pre><span></span><code>并行算子结构：
         ┌→ φ₁(x) → y₁
    x → ─┼→ φ₂(x) → y₂
         └→ φ₃(x) → y₃
</code></pre></div>

<p>这种模式特别适合于多头注意力机制、多尺度特征提取等场景。</p>
<p><strong>融合条件判定</strong>：</p>
<p>两个算子 $\phi_1$ 和 $\phi_2$ 可以水平融合的必要条件：</p>
<ol>
<li><strong>输入兼容性</strong>：$\text{input}(\phi_1) \cap \text{input}(\phi_2) \neq \emptyset$</li>
<li><strong>无数据依赖</strong>：$\nexists$ 路径 $\phi_1 \rightsquigarrow \phi_2$ 或 $\phi_2 \rightsquigarrow \phi_1$</li>
<li><strong>资源约束满足</strong>：$R(\phi_1) + R(\phi_2) \leq R_{max}$</li>
</ol>
<p>其中 $R(\cdot)$ 表示资源需求（寄存器、共享内存等）。</p>
<h3 id="713">7.1.3 混合融合策略</h3>
<p>实际编译器常采用混合策略，同时进行垂直和水平融合：</p>
<div class="codehilite"><pre><span></span><code><span class="n">混合融合示例</span><span class="err">：</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="o">[</span><span class="n">Conv → BN → ReLU</span><span class="o">]</span><span class="w"> </span><span class="err">─┬→</span><span class="w"> </span><span class="o">[</span><span class="n">MaxPool</span><span class="o">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">y₁</span>
<span class="w">                             </span><span class="err">└→</span><span class="w"> </span><span class="o">[</span><span class="n">AvgPool</span><span class="o">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">y₂</span>

<span class="w">    </span><span class="n">垂直融合</span><span class="err">：</span><span class="n">Conv</span><span class="o">-</span><span class="n">BN</span><span class="o">-</span><span class="n">ReLU</span>
<span class="w">    </span><span class="n">水平融合</span><span class="err">：</span><span class="n">MaxPool</span><span class="o">-</span><span class="n">AvgPool</span>
</code></pre></div>

<p><strong>融合决策的成本模型</strong>：</p>
<p>给定算子图 $\mathcal{G} = (V, E)$，融合决策可以形式化为划分问题：</p>
<p>$$
\min_{\mathcal{P}} \sum_{P \in \mathcal{P}} C(P) + \sum_{(P_i, P_j) \in E'} T(P_i, P_j)
$$</p>
<p>其中：</p>
<ul>
<li>$\mathcal{P}$ 是节点集 $V$ 的一个划分</li>
<li>$C(P)$ 是融合块 $P$ 的计算成本</li>
<li>$T(P_i, P_j)$ 是块间数据传输成本</li>
<li>$E'$ 是划分后的块间边集</li>
</ul>
<h3 id="714">7.1.4 自动驾驶场景的特殊考虑</h3>
<p>在自动驾驶场景中，算子融合需要考虑实时性约束：</p>
<ol>
<li><strong>确定性延迟</strong>：融合后的算子执行时间必须可预测</li>
<li><strong>优先级感知</strong>：关键路径（如障碍物检测）的融合优先级更高</li>
<li><strong>异构执行</strong>：某些算子可能需要在不同硬件上执行（GPU/DSP/NPU）</li>
</ol>
<p><strong>延迟约束下的融合</strong>：</p>
<p>设系统延迟上界为 $L_{max}$，则融合决策需满足：</p>
<p>$$
\max_{path \in \text{CriticalPaths}} \sum_{P \in path} L(P) \leq L_{max}
$$</p>
<p>其中 $L(P)$ 是融合块 $P$ 的延迟。</p>
<h2 id="72">7.2 融合规则与模式匹配</h2>
<p>算子融合的自动化需要定义清晰的融合规则和高效的模式匹配算法。本节介绍如何形式化融合规则并实现高效的图模式匹配。</p>
<h3 id="721">7.2.1 融合规则的形式化定义</h3>
<p>融合规则可以表示为模式-动作对 $(Pattern, Action)$：</p>
<p><strong>模式定义语言</strong>：</p>
<p>$$
Pattern ::= Op | Pattern \rightarrow Pattern | Pattern \parallel Pattern | Pattern^*
$$</p>
<p>其中：</p>
<ul>
<li>$Op$ 表示基本算子</li>
<li>$\rightarrow$ 表示顺序连接</li>
<li>$\parallel$ 表示并行结构</li>
<li>$*$ 表示重复模式</li>
</ul>
<p><strong>常见融合模式库</strong>：</p>
<ol>
<li>
<p><strong>Element-wise链融合</strong>：
   $$EW^+ ::= (Add | Mul | Activation)^+$$</p>
</li>
<li>
<p><strong>卷积-归一化-激活融合</strong>：
$$CBA ::= Conv \rightarrow BatchNorm \rightarrow Activation$$</p>
</li>
<li>
<p><strong>注意力机制融合</strong>：
$$Attention ::= (Q \parallel K \parallel V) \rightarrow MatMul \rightarrow Softmax \rightarrow MatMul$$</p>
</li>
</ol>
<h3 id="722">7.2.2 图匹配算法</h3>
<p>模式匹配可以转化为子图同构问题。采用 VF2 算法的变种进行高效匹配：</p>
<p><strong>算法框架</strong>：</p>
<div class="codehilite"><pre><span></span><code>算法：FusionPatternMatch
输入：计算图 G = (V, E)，模式集合 P
输出：匹配实例集合 M

1. 初始化 M = ∅
2. 对每个模式 p ∈ P：
   a. 构建模式的特征向量 f(p)
   b. 筛选候选起始节点 C = {v ∈ V | compatible(v, p.root)}
   c. 对每个 c ∈ C：

      - 执行递归匹配 match(c, p.root)
      - 若匹配成功，加入 M
3. 解决匹配冲突（见 7.2.3）
4. 返回 M
</code></pre></div>

<p><strong>匹配复杂度优化</strong>：</p>
<ol>
<li><strong>特征索引</strong>：预计算节点特征，使用哈希表加速查找</li>
<li><strong>剪枝策略</strong>：基于度数、类型等属性提前剪枝</li>
<li><strong>增量匹配</strong>：利用已匹配结果加速后续匹配</li>
</ol>
<p>时间复杂度：$O(|V|^{|P|})$ 最坏情况，实际中通过剪枝可达到 $O(|V| \cdot |P|)$。</p>
<h3 id="723">7.2.3 冲突检测与解决</h3>
<p>多个融合模式可能产生冲突，需要设计冲突解决机制：</p>
<p><strong>冲突类型</strong>：</p>
<ol>
<li><strong>重叠冲突</strong>：两个模式共享节点</li>
<li><strong>资源冲突</strong>：融合后超出硬件资源限制</li>
<li><strong>依赖冲突</strong>：破坏原有数据依赖关系</li>
</ol>
<p><strong>冲突解决策略</strong>：</p>
<p>采用基于收益的贪心算法：
$$
\text{score}(m) = \frac{\text{benefit}(m)}{\text{cost}(m)} \cdot \text{priority}(m)
$$
其中：</p>
<ul>
<li>$\text{benefit}(m)$ = 内存节省 + 延迟减少</li>
<li>$\text{cost}(m)$ = 寄存器使用 + 编译复杂度</li>
<li>$\text{priority}(m)$ = 路径关键度</li>
</ul>
<h3 id="724">7.2.4 动态模式学习</h3>
<p>除了预定义模式，可以通过机器学习发现新的融合模式：</p>
<p><strong>特征提取</strong>：</p>
<p>对于子图 $S = (V_S, E_S)$，提取特征向量：
$$
\vec{f}_S = [\text{op_types}, \text{tensor_shapes}, \text{compute_intensity}, \text{memory_pattern}]
$$
<strong>融合收益预测</strong>：</p>
<p>训练回归模型 $g: \vec{f}_S \rightarrow \mathbb{R}$，预测融合收益：
$$
\hat{y} = g(\vec{f}_S; \theta) = \sigma(W_2 \cdot \text{ReLU}(W_1 \cdot \vec{f}_S + b_1) + b_2)
$$</p>
<h2 id="73">7.3 内存带宽优化</h2>
<p>内存带宽是现代 AI 加速器的主要瓶颈。算子融合通过减少内存访问次数，直接优化带宽利用率。</p>
<h3 id="731">7.3.1 带宽瓶颈分析</h3>
<p><strong>Roofline 模型</strong>：</p>
<p>计算强度（Operational Intensity）定义为：
$$
I = \frac{\text{FLOPs}}{\text{Bytes Accessed}}
$$
性能上界：
$$
P = \min(P_{peak}, I \times B)
$$
其中 $P_{peak}$ 是峰值计算性能，$B$ 是内存带宽。</p>
<div class="codehilite"><pre><span></span><code>Roofline 模型示意图：
    性能
    ↑
    │     ╱─────── 计算受限区域 (P_peak)
    │    ╱ 
    │   ╱  带宽受限区域
    │  ╱   (斜率 = B)
    │ ╱
    └────────────────→ 计算强度
         I_c
</code></pre></div>

<p>临界点 $I_c = \frac{P_{peak}}{B}$ 决定了算子是计算受限还是带宽受限。</p>
<h3 id="732">7.3.2 融合对带宽的影响</h3>
<p><strong>单算子带宽需求</strong>：</p>
<p>对于算子 $\phi$，带宽需求为：
$$
BW(\phi) = \frac{M_{in}(\phi) + M_{out}(\phi)}{T_{exec}(\phi)}
$$
<strong>融合后的带宽优化</strong>：</p>
<p>融合 $n$ 个算子后：
$$
BW_{fused} = \frac{M_{in}(\phi_1) + M_{out}(\phi_n) + \sum_{i=1}^{n-1} M_{intermediate}^{reg}(\phi_i)}{T_{exec}^{fused}}
$$
其中 $M_{intermediate}^{reg}$ 表示通过寄存器传递的中间数据（不占用全局内存带宽）。</p>
<p><strong>带宽节省率</strong>：
$$
\eta_{BW} = 1 - \frac{BW_{fused}}{\sum_{i=1}^n BW(\phi_i)} = 1 - \frac{M_{boundary}}{M_{total}}
$$</p>
<h3 id="733">7.3.3 缓存局部性优化</h3>
<p>融合可以改善缓存局部性，减少缓存缺失：</p>
<p><strong>时间局部性增强</strong>：</p>
<p>融合减少了数据重用的时间间隔：
$$
\Delta t_{reuse} = t_{consume} - t_{produce}
$$
融合后 $\Delta t_{reuse} \approx 0$，数据在缓存中的概率提高。</p>
<p><strong>空间局部性优化</strong>：</p>
<p>通过循环变换优化访问模式：</p>
<div class="codehilite"><pre><span></span><code><span class="n">循环嵌套优化</span><span class="err">（</span><span class="n">伪代码</span><span class="err">）：</span>
<span class="n">未融合</span><span class="err">：</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="o">[</span><span class="n">0, N):</span>
<span class="n">    tmp[i</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">φ₁</span><span class="p">(</span><span class="n">x</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">)</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="o">[</span><span class="n">0, N):</span>
<span class="n">    y[i</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">φ₂</span><span class="p">(</span><span class="n">tmp</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">)</span>

<span class="n">融合后</span><span class="err">：</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="o">[</span><span class="n">0, N) step TILE_SIZE:</span>
<span class="n">    for j in [i, min(i+TILE_SIZE, N)):</span>
<span class="n">      y[j</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">φ₂</span><span class="p">(</span><span class="n">φ₁</span><span class="p">(</span><span class="n">x</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="p">))</span><span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">寄存器级数据传递</span>
</code></pre></div>

<h3 id="734">7.3.4 预取策略协同</h3>
<p>算子融合需要与硬件预取机制协同：</p>
<p><strong>预取距离计算</strong>：
$$
d_{prefetch} = \lceil \frac{L_{mem}}{T_{compute}} \rceil
$$
其中 $L_{mem}$ 是内存延迟，$T_{compute}$ 是计算时间。</p>
<p><strong>融合对预取的影响</strong>：</p>
<ol>
<li>融合增加了计算密度，可能需要调整预取距离</li>
<li>减少了不规则访问，提高预取命中率</li>
<li>需要考虑融合后的工作集大小对缓存的压力</li>
</ol>
<h2 id="74">7.4 融合的收益分析模型</h2>
<p>准确的收益分析模型是制定融合决策的基础。本节建立综合考虑性能、功耗和资源的分析框架。</p>
<h3 id="741">7.4.1 性能预测模型</h3>
<p><strong>静态分析模型</strong>：</p>
<p>融合后的执行时间预测：
$$
T_{fused} = \max(T_{compute}, T_{memory}) + T_{overhead}
$$
其中：</p>
<ul>
<li>$T_{compute} = \frac{\sum_{i} \text{FLOPs}(\phi_i)}{P_{throughput}}$</li>
<li>$T_{memory} = \frac{M_{in} + M_{out}}{B_{effective}}$</li>
<li>$T_{overhead}$ = 核函数启动 + 同步开销</li>
</ul>
<p><strong>动态校正因子</strong>：</p>
<p>实际执行时间通常需要校正：
$$
T_{actual} = T_{fused} \times (1 + \alpha_{cache} + \alpha_{conflict} + \alpha_{divergence})
$$
校正因子通过 profiling 获得。</p>
<h3 id="742-">7.4.2 成本-收益分析</h3>
<p><strong>多目标优化框架</strong>：</p>
<p>融合决策需要平衡多个目标：
$$
\text{Objective} = w_1 \cdot \Delta T + w_2 \cdot \Delta M + w_3 \cdot \Delta E - w_4 \cdot C_{compile}
$$
其中：</p>
<ul>
<li>$\Delta T$ = 延迟改善</li>
<li>$\Delta M$ = 内存节省</li>
<li>$\Delta E$ = 能耗降低</li>
<li>$C_{compile}$ = 编译复杂度增加</li>
</ul>
<p><strong>帕累托最优解</strong>：</p>
<p>在多目标空间中寻找帕累托前沿：
$$
\text{Pareto}(\mathcal{F}) = \{f \in \mathcal{F} | \nexists g \in \mathcal{F}, g \succ f\}
$$</p>
<h3 id="743">7.4.3 动态决策机制</h3>
<p>运行时可能需要动态调整融合策略：</p>
<p><strong>自适应阈值</strong>：</p>
<p>根据运行时统计信息调整融合阈值：
$$
\theta_{t+1} = \theta_t + \eta \cdot (R_{observed} - R_{predicted})
$$
其中 $R$ 表示收益，$\eta$ 是学习率。</p>
<p><strong>在线学习框架</strong>：</p>
<p>使用强化学习优化融合决策：</p>
<ul>
<li>状态空间：$s = [\text{graph_features}, \text{hardware_state}]$</li>
<li>动作空间：$a \in \{fuse, not_fuse\}$</li>
<li>奖励函数：$r = -T_{actual} - \lambda \cdot M_{used}$</li>
</ul>
<h3 id="744-transformer">7.4.4 案例分析：Transformer 模型</h3>
<p>以 BERT 模型为例分析融合收益：</p>
<p><strong>注意力块融合</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">原始计算流程</span><span class="err">：</span>
<span class="n">Q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Linear</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Linear</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">V</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Linear</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="err">→</span><span class="w"> </span><span class="n">Scores</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Q</span><span class="w"> </span><span class="err">@</span><span class="w"> </span><span class="n">K</span><span class="o">^</span><span class="n">T</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="n">Attention</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Softmax</span><span class="p">(</span><span class="n">Scores</span><span class="p">)</span><span class="w"> </span><span class="err">@</span><span class="w"> </span><span class="n">V</span>

<span class="n">融合方案</span><span class="err">：</span>
<span class="o">[</span><span class="n">QKV生成融合</span><span class="o">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="o">[</span><span class="n">注意力计算融合</span><span class="o">]</span>
</code></pre></div>

<p><strong>性能分析</strong>：</p>
<ul>
<li>内存访问减少：$3 \times d_{model} \times seq_len \times batch$ 字节</li>
<li>核函数调用：从 6 次减少到 2 次</li>
<li>实测加速比：1.3-1.5x（取决于序列长度）</li>
</ul>
<p><strong>具身智能场景优化</strong>：</p>
<p>在机器人控制中，融合可以显著降低感知-决策延迟：</p>
<div class="codehilite"><pre><span></span><code>感知管线融合：
[图像预处理] → [特征提取] → [目标检测] → [深度估计]
    ↓
[融合后的端到端感知模块]

延迟改善：50ms → 30ms（40% 降低）
</code></pre></div>

<h2 id="_1">本章小结</h2>
<p>算子融合是 AI 编译器优化的核心技术，通过减少内存访问和核函数调用开销，显著提升推理性能。本章的关键要点包括：</p>
<ol>
<li>
<p><strong>融合策略分类</strong>：垂直融合优化生产者-消费者链，水平融合并行执行独立算子，混合策略结合两者优势</p>
</li>
<li>
<p><strong>关键公式回顾</strong>：
   - 垂直融合加速比：$S = n$（n 为融合算子数）
   - 计算强度：$I = \frac{\text{FLOPs}}{\text{Bytes Accessed}}$
   - 带宽节省率：$\eta_{BW} = 1 - \frac{M_{boundary}}{M_{total}}$
   - 融合决策目标：$\min_{\mathcal{P}} \sum_{P \in \mathcal{P}} C(P) + \sum_{(P_i, P_j) \in E'} T(P_i, P_j)$</p>
</li>
<li>
<p><strong>模式匹配机制</strong>：通过形式化的模式定义语言和高效的子图匹配算法，自动识别可融合的算子组合</p>
</li>
<li>
<p><strong>内存带宽优化</strong>：融合直接减少全局内存访问，提高缓存局部性，是解决带宽瓶颈的有效手段</p>
</li>
<li>
<p><strong>收益分析框架</strong>：综合考虑性能、内存、功耗等多个维度，通过成本模型指导融合决策</p>
</li>
<li>
<p><strong>场景化优化</strong>：在自动驾驶和具身智能场景中，需要特别考虑实时性约束和确定性延迟要求</p>
</li>
</ol>
<p>算子融合的成功实施需要深入理解硬件特性、准确的性能建模和灵活的策略调整。随着模型规模和硬件复杂度的增加，自动化和智能化的融合策略将变得越来越重要。</p>
<h2 id="_2">练习题</h2>
<h3 id="_3">基础题</h3>
<p><strong>练习 7.1</strong>：给定算子链 Conv → BatchNorm → ReLU → MaxPool，其中 Conv 输出张量大小为 $256 \times 112 \times 112 \times 32$（NHWC 格式），数据类型为 FP16。假设内存带宽为 900 GB/s，计算：</p>
<ol>
<li>未融合时的总内存传输量</li>
<li>完全融合后的内存传输量</li>
<li>理论带宽节省率</li>
</ol>
<details>
<summary>答案</summary>
<ol>
<li>
<p>未融合的内存传输：
   - Conv 输出：$256 \times 112 \times 112 \times 32 \times 2 = 205,520,896$ 字节
   - BatchNorm 输入/输出：$2 \times 205,520,896 = 411,041,792$ 字节
   - ReLU 输入/输出：$2 \times 205,520,896 = 411,041,792$ 字节
   - MaxPool 输入：$205,520,896$ 字节
   - MaxPool 输出（2×2 池化）：$256 \times 56 \times 56 \times 32 \times 2 = 51,380,224$ 字节
   - 总计：$1,284,505,600$ 字节 ≈ 1.20 GB</p>
</li>
<li>
<p>完全融合后的内存传输：
   - 输入（Conv 的输入，需要根据卷积核大小计算，假设为 3×3）：
     $256 \times 114 \times 114 \times 3 \times 2 = 19,968,768$ 字节</p>
</li>
</ol>
<ul>
<li>输出（MaxPool 后）：$51,380,224$ 字节</li>
<li>总计：$71,348,992$ 字节 ≈ 0.066 GB</li>
</ul>
<ol start="3">
<li>带宽节省率：
$$\eta = 1 - \frac{71,348,992}{1,284,505,600} = 94.4\%$$</li>
</ol>
</details>
<p><strong>练习 7.2</strong>：使用 Roofline 模型分析一个矩阵乘法算子 $C = A \times B$，其中 $A \in \mathbb{R}^{1024 \times 768}$，$B \in \mathbb{R}^{768 \times 512}$。硬件峰值性能为 312 TFLOPS（FP16），内存带宽为 2 TB/s。判断该算子是计算受限还是带宽受限？</p>
<p><em>Hint</em>：计算 FLOPs 和内存访问量，求出计算强度。</p>
<details>
<summary>答案</summary>
<ol>
<li>
<p>计算 FLOPs：
   - 矩阵乘法 FLOPs = $2 \times M \times N \times K = 2 \times 1024 \times 512 \times 768 = 805,306,368$ FLOPs</p>
</li>
<li>
<p>内存访问量（FP16，每个元素 2 字节）：
   - 读取 A：$1024 \times 768 \times 2 = 1,572,864$ 字节
   - 读取 B：$768 \times 512 \times 2 = 786,432$ 字节
   - 写入 C：$1024 \times 512 \times 2 = 1,048,576$ 字节
   - 总计：$3,407,872$ 字节</p>
</li>
<li>
<p>计算强度：
$$I = \frac{805,306,368}{3,407,872} = 236.3 \text{ FLOPs/Byte}$$</p>
</li>
<li>
<p>临界点：
$$I_c = \frac{312 \times 10^{12}}{2 \times 10^{12}} = 156 \text{ FLOPs/Byte}$$</p>
</li>
<li>
<p>结论：$I = 236.3 &gt; I_c = 156$，该算子是<strong>计算受限</strong>的。</p>
</li>
</ol>
</details>
<p><strong>练习 7.3</strong>：设计一个简单的融合规则，用形式化语言描述 "连续的逐元素操作可以融合" 这一模式，并给出三个符合该模式的具体算子链示例。</p>
<details>
<summary>答案</summary>
<p>融合规则形式化定义：
$$\text{ElementwiseChain} ::= (Unary | Binary)^+ $$
其中：</p>
<ul>
<li>$Unary ::= \{ReLU, Sigmoid, Tanh, Exp, Log, Neg, Abs, ...\}$</li>
<li>$Binary ::= \{Add, Sub, Mul, Div, Maximum, Minimum, ...\}$</li>
</ul>
<p>匹配条件：</p>
<ul>
<li>所有算子的输入输出形状相同</li>
<li>不包含 reduction 操作</li>
<li>中间结果不被其他算子使用</li>
</ul>
<p>三个具体示例：</p>
<ol>
<li>$x \rightarrow Add(y) \rightarrow ReLU \rightarrow Mul(scale)$</li>
<li>$x \rightarrow Sigmoid \rightarrow Mul(gate) \rightarrow Add(bias)$</li>
<li>$x \rightarrow Abs \rightarrow Log \rightarrow Neg \rightarrow Exp$</li>
</ol>
</details>
<h3 id="_4">挑战题</h3>
<p><strong>练习 7.4</strong>：考虑一个简化的注意力机制计算：
$$\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$
其中 $Q, K, V \in \mathbb{R}^{B \times L \times D}$，$B=32$（批大小），$L=512$（序列长度），$D=768$（隐藏维度）。设计一个两阶段融合方案，并分析每个阶段的内存访问模式和潜在的优化机会。</p>
<p><em>Hint</em>：考虑哪些操作共享输入，哪些产生大的中间结果。</p>
<details>
<summary>答案</summary>
<p><strong>两阶段融合方案</strong>：</p>
<p>阶段 1：QKV 生成与注意力分数计算</p>
<div class="codehilite"><pre><span></span><code><span class="n">输入</span><span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="o">[</span><span class="n">Q,K,V 并行生成</span><span class="o">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="o">[</span><span class="n">QK^T 计算 + scale</span><span class="o">]</span><span class="w"> </span><span class="err">→</span><span class="w"> </span><span class="o">[</span><span class="n">Softmax</span><span class="o">]</span>
</code></pre></div>

<p>阶段 2：注意力加权</p>
<div class="codehilite"><pre><span></span><code>[Softmax 输出] + V → [矩阵乘法] → 输出
</code></pre></div>

<p><strong>内存访问分析</strong>：</p>
<p>阶段 1：</p>
<ul>
<li>输入：读取 X 一次（$B \times L \times D \times 4$ 字节，FP32）</li>
<li>中间结果：QK^T 矩阵很大（$B \times L \times L \times 4 = 32 \times 512 \times 512 \times 4 = 33,554,432$ 字节）</li>
<li>优化机会：
  1. 使用分块（tiling）减少 QK^T 的内存占用
  2. Flash Attention 风格的融合，避免材化完整的注意力矩阵
  3. 在线 softmax 计算，减少两遍扫描</li>
</ul>
<p>阶段 2：</p>
<ul>
<li>相对简单的矩阵乘法</li>
<li>可以与下游的 FFN 层进一步融合</li>
</ul>
<p><strong>进一步优化</strong>：</p>
<p>采用 Flash Attention 算法，将整个注意力计算融合为单个核函数：</p>
<ul>
<li>分块大小：$B_r = B_c = \sqrt{\frac{M}{4d}}$（M 为 SRAM 大小）</li>
<li>内存访问复杂度：从 $O(L^2)$ 降低到 $O(L)$</li>
<li>实际加速：2-4x（取决于序列长度）</li>
</ul>
</details>
<p><strong>练习 7.5</strong>：在 NUMA 系统上进行算子融合时，需要考虑跨 NUMA 节点的数据访问开销。假设有两个 NUMA 节点，本地内存访问延迟为 100ns，远程访问延迟为 150ns。设计一个 NUMA 感知的融合成本模型。</p>
<details>
<summary>答案</summary>
<p><strong>NUMA 感知成本模型</strong>：</p>
<ol>
<li>
<p>数据放置矩阵：
   设 $P \in \{0,1\}^{n \times 2}$ 表示 n 个张量在 2 个 NUMA 节点上的放置，$P_{ij} = 1$ 表示张量 i 在节点 j 上。</p>
</li>
<li>
<p>访问成本矩阵：
$$C_{access}(i,j) = \begin{cases}
   100 \cdot M_i &amp; \text{if } P_{i,j} = 1 \text{ (本地访问)} \\
   150 \cdot M_i &amp; \text{if } P_{i,j} = 0 \text{ (远程访问)}
   \end{cases}$$</p>
</li>
<li>
<p>融合决策函数：
$$Cost_{NUMA}(F) = \sum_{op \in F} \sum_{node} C_{access}(input(op), node) \cdot P_{op,node}$$</p>
</li>
<li>
<p>优化目标：
$$\min_{P,F} Cost_{NUMA}(F) + \lambda \cdot Migration(P)$$
其中 $Migration(P)$ 是数据迁移开销。</p>
</li>
<li>
<p>融合约束：
   - 融合块内的算子应尽量在同一 NUMA 节点执行
   - 大的中间结果应避免跨节点传输
   - 考虑负载均衡，避免单节点过载</p>
</li>
<li>
<p>实际策略：
   - 优先融合同一 NUMA 节点上的算子
   - 对于必须跨节点的融合，评估收益是否大于 NUMA 开销
   - 使用亲和性调度确保融合块在预期节点执行</p>
</li>
</ol>
</details>
<p><strong>练习 7.6</strong>：动态 shape 场景下，融合决策可能需要在运行时进行。设计一个基于历史执行信息的自适应融合策略，包括：</p>
<ol>
<li>需要收集哪些运行时信息</li>
<li>如何根据这些信息调整融合决策</li>
<li>如何处理 shape 变化导致的重编译开销</li>
</ol>
<details>
<summary>答案</summary>
<p><strong>自适应融合策略设计</strong>：</p>
<ol>
<li><strong>运行时信息收集</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code>ProfileData = {
  shape_histogram: Map&lt;Shape, Count&gt;,
  fusion_perf: Map&lt;(FusionPattern, Shape), Latency&gt;,
  memory_pressure: TimeSeries&lt;MemUsage&gt;,
  recompile_cost: Map&lt;Shape, CompileTime&gt;
}
</code></pre></div>

<ol start="2">
<li><strong>决策调整机制</strong>：</li>
</ol>
<p>a) Shape 聚类与桶化：
$$Buckets = \text{KMeans}(\{s_1, s_2, ..., s_n\}, k)$$
b) 融合收益预测：
$$Benefit(f, s) = \alpha \cdot P(s) \cdot Speedup(f, bucket(s)) - \beta \cdot RecompileCost(s)$$
其中 $P(s)$ 是 shape s 的出现概率。</p>
<p>c) 在线决策树：
   <code>if shape in cache:
     use cached fusion plan
   elif similar_shape in cache:
     adapt plan with minor adjustments
   else:
     if expected_reuse &gt; threshold:
       compile new fusion plan
     else:
       use conservative default plan</code></p>
<ol start="3">
<li><strong>重编译开销处理</strong>：</li>
</ol>
<p>a) 两级缓存：</p>
<ul>
<li>L1：精确 shape 匹配（快速）</li>
<li>L2：shape 范围匹配（需要微调）</li>
</ul>
<p>b) 异步编译：</p>
<div class="codehilite"><pre><span></span><code>if predict_future_shape(history) not in cache:
  trigger_async_compilation()
</code></pre></div>

<p>c) 编译预算控制：
$$CompileBudget_t = CompileBudget_{t-1} + \alpha - CompileCost_t$$
只有预算充足时才触发重编译。</p>
<ol start="4">
<li><strong>实施细节</strong>：
   - 使用滑动窗口维护 shape 分布
   - 指数加权移动平均更新性能统计
   - 设置最大缓存大小，LRU 淘汰
   - 在关键路径上使用保守策略</li>
</ol>
</details>
<p><strong>练习 7.7</strong>：在自动驾驶场景中，某些融合可能会增加延迟抖动（jitter），影响实时性。设计一个考虑延迟分布（而非仅平均延迟）的融合决策框架，确保 99 分位延迟满足要求。</p>
<details>
<summary>答案</summary>
<p><strong>延迟分布感知的融合框架</strong>：</p>
<ol>
<li><strong>延迟分布建模</strong>：</li>
</ol>
<p>使用对数正态分布建模融合后的延迟：
$$T \sim \text{LogNormal}(\mu, \sigma^2)$$
参数估计：
$$\mu = \ln(\text{median}(T)), \quad \sigma = \sqrt{\ln(1 + CV^2)}$$
其中 $CV$ 是变异系数。</p>
<ol start="2">
<li>
<p><strong>99 分位延迟约束</strong>：
$$P(T \leq T_{99}) = 0.99$$
对于对数正态分布：
$$T_{99} = \exp(\mu + \sigma \cdot \Phi^{-1}(0.99))$$
其中 $\Phi^{-1}$ 是标准正态分布的逆函数。</p>
</li>
<li>
<p><strong>融合决策目标</strong>：
$$\min_F \mathbb{E}[T] \quad \text{s.t.} \quad T_{99} \leq T_{max}$$
转化为：
$$\min_F \exp(\mu + \frac{\sigma^2}{2}) \quad \text{s.t.} \quad \exp(\mu + 2.326\sigma) \leq T_{max}$$</p>
</li>
<li>
<p><strong>抖动来源分析</strong>：</p>
</li>
</ol>
<ul>
<li>缓存竞争：$\sigma_{cache}^2$</li>
<li>内存分配：$\sigma_{alloc}^2$  </li>
<li>硬件调度：$\sigma_{sched}^2$</li>
</ul>
<p>总体方差：$\sigma^2 = \sigma_{cache}^2 + \sigma_{alloc}^2 + \sigma_{sched}^2$</p>
<ol start="5">
<li><strong>融合策略</strong>：</li>
</ol>
<p>a) 抖动预测模型：
$$\sigma_{fused}^2 = f(|ops|, memory_pattern, resource_usage)$$
b) 安全融合条件：</p>
<div class="codehilite"><pre><span></span><code>can_fuse = (T99_fused &lt; T_max) AND 
           (jitter_fused &lt; jitter_baseline * 1.2)
</code></pre></div>

<p>c) 优先级调整：</p>
<ul>
<li>关键路径（障碍物检测）：使用保守融合</li>
<li>非关键路径（地图更新）：允许更激进融合</li>
</ul>
<ol start="6">
<li><strong>运行时监控</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code>实时统计延迟分布
if percentile_99 &gt; threshold:
  rollback to conservative fusion
  adjust fusion parameters
</code></pre></div>

</details>
<p><strong>练习 7.8</strong>（开放性思考题）：未来的 AI 编译器可能需要支持投机执行，例如在大语言模型的投机解码中。讨论算子融合如何与投机执行机制协同工作，需要解决哪些新的挑战？</p>
<details>
<summary>参考思路</summary>
<p><strong>投机执行与算子融合的协同</strong>：</p>
<ol>
<li><strong>挑战分析</strong>：</li>
</ol>
<p>a) 投机路径的融合决策：</p>
<ul>
<li>不同投机分支可能有不同的最优融合方案</li>
<li>需要平衡投机成功率与融合收益</li>
<li>回滚成本需要纳入考虑</li>
</ul>
<p>b) 状态管理复杂性：</p>
<ul>
<li>融合后的算子状态更大，回滚开销增加</li>
<li>需要细粒度的检查点机制</li>
<li>中间结果的保存策略</li>
</ul>
<p>c) 资源竞争：</p>
<ul>
<li>投机执行占用额外资源</li>
<li>融合可能加剧资源竞争</li>
<li>需要动态资源分配</li>
</ul>
<ol start="2">
<li><strong>可能的解决方案</strong>：</li>
</ol>
<p>a) 分层融合策略：</p>
<div class="codehilite"><pre><span></span><code>Layer 1: 确定性融合（always beneficial）
Layer 2: 投机友好融合（low rollback cost）
Layer 3: 条件融合（based on speculation success）
</code></pre></div>

<p>b) 投机感知的成本模型：
$$Cost = p_{success} \cdot Cost_{fused} + (1-p_{success}) \cdot (Cost_{unfused} + Cost_{rollback})$$</p>
<p>c) 增量式融合：</p>
<ul>
<li>先执行部分融合</li>
<li>根据投机结果决定是否继续融合</li>
<li>支持融合的部分回滚</li>
</ul>
<ol start="3">
<li><strong>新的研究方向</strong>：</li>
</ol>
<ul>
<li>预测投机成功率的机器学习模型</li>
<li>融合粒度的自适应调整</li>
<li>硬件支持的快速状态保存/恢复</li>
<li>编译时投机路径分析</li>
<li>多版本融合代码生成</li>
</ul>
<ol start="4">
<li><strong>实际应用场景</strong>：</li>
</ol>
<ul>
<li>LLM 投机解码：draft model 的融合策略</li>
<li>分支预测：条件执行路径的预融合</li>
<li>提前退出网络：不同退出点的融合方案</li>
<li>动态计算图：运行时图结构预测与融合</li>
</ul>
</details>
<h2 id="_5">常见陷阱与错误</h2>
<ol>
<li>
<p><strong>过度融合</strong>：并非所有算子都适合融合，过度融合可能导致：
   - 寄存器溢出，性能反而下降
   - 编译时间exponential增长
   - 调试困难，错误定位复杂</p>
</li>
<li>
<p><strong>忽视硬件约束</strong>：
   - 不同硬件的融合收益差异很大
   - GPU 的 shared memory 限制
   - TPU 的 systolic array 对融合模式的要求
   - 移动端的功耗约束</p>
</li>
<li>
<p><strong>静态分析的局限</strong>：
   - 运行时行为可能与静态预测不符
   - 缓存效应难以准确建模
   - 需要 profiling 数据校正</p>
</li>
<li>
<p><strong>依赖分析错误</strong>：
   - 忽视隐式依赖（如随机数生成器状态）
   - 错误处理 inplace 操作
   - 别名分析不准确导致错误融合</p>
</li>
<li>
<p><strong>数值稳定性问题</strong>：
   - 融合可能改变计算顺序
   - 浮点运算的非结合性
   - 需要保证数值一致性</p>
</li>
</ol>
<h2 id="_6">最佳实践检查清单</h2>
<h3 id="_7">设计阶段</h3>
<ul>
<li>[ ] 明确定义融合规则和优先级</li>
<li>[ ] 建立准确的成本模型</li>
<li>[ ] 考虑目标硬件特性</li>
<li>[ ] 设计冲突解决机制</li>
<li>[ ] 规划动态 shape 支持</li>
</ul>
<h3 id="_8">实现阶段</h3>
<ul>
<li>[ ] 实现高效的模式匹配算法</li>
<li>[ ] 正确处理内存分配和生命周期</li>
<li>[ ] 保证融合的正确性（依赖、数值）</li>
<li>[ ] 添加融合的开关和配置选项</li>
<li>[ ] 实现性能 profiling 接口</li>
</ul>
<h3 id="_9">优化阶段</h3>
<ul>
<li>[ ] 收集真实负载的 profiling 数据</li>
<li>[ ] 基于数据调整融合策略</li>
<li>[ ] 优化编译时间与运行时间的平衡</li>
<li>[ ] 验证不同 batch size 下的表现</li>
<li>[ ] 测试边界条件和异常情况</li>
</ul>
<h3 id="_10">部署阶段</h3>
<ul>
<li>[ ] 提供融合效果的可视化工具</li>
<li>[ ] 记录融合决策日志便于调试</li>
<li>[ ] 监控生产环境的融合效果</li>
<li>[ ] 建立融合策略的 A/B 测试机制</li>
<li>[ ] 准备回滚方案</li>
</ul>
            </article>
            
            <nav class="page-nav"><a href="chapter6.html" class="nav-link prev">← 第 6 章：数据布局优化</a><a href="chapter8.html" class="nav-link next">第 8 章：自动微分与梯度优化 →</a></nav>
        </main>
    </div>
</body>
</html>